{"cells":[{"cell_type":"code","metadata":{"id":"NcG0IxjY0cqN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196908132,"user_tz":300,"elapsed":528,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["import os\n","import glob\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvMq-KpR0cqS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196908988,"user_tz":300,"elapsed":307,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["# Define working directory\n","os.chdir(r\"C:\\Users\\Cristina Bardan\\Desktop\\Repositories\\FinalProject-Spotify\\Original_data\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-ewU33W0cqV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1593196911081,"user_tz":300,"elapsed":1331,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"d879194f-8c82-4f01-b1e4-c37861cc10b0"},"source":["# Use glob to match the pattern ‘csv’\n","extension = 'csv'\n","all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n","\n","# Combine all files in the list and export as CSV\n","df = pd.concat([pd.read_csv(f) for f in all_filenames ])\n","df.reset_index(drop=True, inplace=True)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKjuVkuQ0cqZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1593196913124,"user_tz":300,"elapsed":321,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"17e77d62-f709-4494-83a5-c18f75520286"},"source":["df2 = df.drop(['track', 'artist', 'uri'], axis=1)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqlHQ-yC0cqf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1593196916115,"user_tz":300,"elapsed":332,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"cb9bc354-9057-48df-dcc0-a1b923e9f715"},"source":["#Validation of correlation between variables\n","import numpy as np \n","df3=df2.corr()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bkdcEPG1ibv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196937815,"user_tz":300,"elapsed":7976,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"tags":[]},"source":["# Sin chorus_hit y speechiness\n","data = df2.values\n","X = df2[['danceability', 'energy', 'key', 'loudness','mode', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo', 'duration_ms', 'time_signature', 'sections']]  \n","y = data[:, 15]\n","print(data.shape, X.shape, y.shape)\n","data"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"(41106, 16) (41106, 13) (41106,)\n"},{"output_type":"execute_result","data":{"text/plain":"array([[ 0.578  ,  0.471  ,  4.     , ..., 30.88059, 13.     ,  1.     ],\n       [ 0.704  ,  0.854  , 10.     , ..., 41.51106, 10.     ,  1.     ],\n       [ 0.162  ,  0.836  ,  9.     , ..., 65.32887, 13.     ,  0.     ],\n       ...,\n       [ 0.562  ,  0.314  , 10.     , ..., 21.11763, 10.     ,  1.     ],\n       [ 0.622  ,  0.781  ,  7.     , ..., 47.13558, 11.     ,  0.     ],\n       [ 0.664  ,  0.739  ,  2.     , ..., 42.50341, 14.     ,  1.     ]])"},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"jY2Jscy60cqq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196941239,"user_tz":300,"elapsed":834,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABiuRgdQ0cqt","colab_type":"text"},"source":["## Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"hfEdBDfb0cqu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1593196944475,"user_tz":300,"elapsed":342,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"64bd50bf-4868-46a2-f290-9401841f5581"},"source":["#Scale features (X) using MinMaxScaler\n","from sklearn.preprocessing import MinMaxScaler\n","X_scaler = MinMaxScaler(feature_range=(0,1)).fit(X_train)\n","\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test) \n","\n","X_train_scaled"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[0.78947368, 0.52283395, 0.81818182, ..., 0.05569473, 0.8       ,\n        0.06508876],\n       [0.54048583, 0.83094117, 0.81818182, ..., 0.03957652, 0.8       ,\n        0.04142012],\n       [0.5       , 0.66588373, 0.81818182, ..., 0.03176775, 0.8       ,\n        0.03550296],\n       ...,\n       [0.57692308, 0.36777999, 0.81818182, ..., 0.09203629, 0.8       ,\n        0.09467456],\n       [0.41902834, 0.16070793, 0.63636364, ..., 0.0441886 , 0.8       ,\n        0.04733728],\n       [0.29554656, 0.24873856, 0.81818182, ..., 0.0506431 , 0.6       ,\n        0.06508876]])"},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Uy2UDESH0cqy","colab_type":"text"},"source":["One-hot encode the labels"]},{"cell_type":"code","metadata":{"id":"2bgX_eKc0cqz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1593196947976,"user_tz":300,"elapsed":1876,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"823117d9-f80a-4255-fc73-47fca33d0855"},"source":["#One-hot encode output labels (y)\n","from tensorflow.keras.utils import to_categorical\n","y_train_categorical = to_categorical(y_train)\n","y_test_categorical = to_categorical(y_test)\n","\n","y_train_categorical"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[0., 1.],\n       [1., 0.],\n       [0., 1.],\n       ...,\n       [0., 1.],\n       [0., 1.],\n       [1., 0.]], dtype=float32)"},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"bdxnMFS40cq2","colab_type":"text"},"source":["## Creating and defining our Deep Learning Model Architecture"]},{"cell_type":"code","metadata":{"id":"Vengxhzv0cq3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196965436,"user_tz":300,"elapsed":313,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["#Create a sequential model\n","from tensorflow.keras.models import Sequential\n","model = Sequential() \n","\n","from tensorflow.keras.layers import Dense\n","number_inputs = 13  \n","\n","#Create hidden layers\n","model.add(Dense(units=14,activation='relu', input_dim=number_inputs))\n","model.add(Dense(units=120,activation='relu'))\n","model.add(Dense(units=80,activation='relu'))\n","\n","\n","#Create output layer\n","number_classes = 2\n","model.add(Dense(units=number_classes, activation='softmax')) "],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-z2bcd60cq5","colab_type":"text"},"source":["Number of Hidden Nodes \n","https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=The%20number%20of%20hidden%20neurons,size%20of%20the%20input%20layer."]},{"cell_type":"code","metadata":{"tags":[],"id":"e68kh-j-0cq6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1593196967395,"user_tz":300,"elapsed":388,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"240a8955-0653-4a48-e064-65109ea6ecbc"},"source":["#Model Summary\n","model.summary() "],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 14)                196       \n_________________________________________________________________\ndense_1 (Dense)              (None, 120)               1800      \n_________________________________________________________________\ndense_2 (Dense)              (None, 80)                9680      \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 162       \n=================================================================\nTotal params: 11,838\nTrainable params: 11,838\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"cell_type":"code","metadata":{"id":"wJTml5b60cq9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196969414,"user_tz":300,"elapsed":440,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["#Compile the Model\n","import tensorflow as tf\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4H8OtKeZ0cq_","colab_type":"text"},"source":["## Training the Model"]},{"cell_type":"code","metadata":{"tags":[],"id":"-CFXztyU0crA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593197036312,"user_tz":300,"elapsed":64859,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"85fe4fa3-989a-454d-e685-aa5c53888c88"},"source":["#Training the Model\n","history = model.fit(X_train_scaled, y_train_categorical, epochs=500, batch_size=2000, shuffle=True, verbose=2)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/500\n16/16 - 0s - loss: 0.6684 - accuracy: 0.6340\nEpoch 2/500\n16/16 - 0s - loss: 0.6125 - accuracy: 0.6950\nEpoch 3/500\n16/16 - 0s - loss: 0.5569 - accuracy: 0.7097\nEpoch 4/500\n16/16 - 0s - loss: 0.5406 - accuracy: 0.7213\nEpoch 5/500\n16/16 - 0s - loss: 0.5337 - accuracy: 0.7294\nEpoch 6/500\n16/16 - 0s - loss: 0.5290 - accuracy: 0.7328\nEpoch 7/500\n16/16 - 0s - loss: 0.5257 - accuracy: 0.7357\nEpoch 8/500\n16/16 - 0s - loss: 0.5228 - accuracy: 0.7389\nEpoch 9/500\n16/16 - 0s - loss: 0.5202 - accuracy: 0.7407\nEpoch 10/500\n16/16 - 0s - loss: 0.5178 - accuracy: 0.7393\nEpoch 11/500\n16/16 - 0s - loss: 0.5159 - accuracy: 0.7414\nEpoch 12/500\n16/16 - 0s - loss: 0.5134 - accuracy: 0.7437\nEpoch 13/500\n16/16 - 0s - loss: 0.5111 - accuracy: 0.7445\nEpoch 14/500\n16/16 - 0s - loss: 0.5100 - accuracy: 0.7449\nEpoch 15/500\n16/16 - 0s - loss: 0.5095 - accuracy: 0.7464\nEpoch 16/500\n16/16 - 0s - loss: 0.5080 - accuracy: 0.7471\nEpoch 17/500\n16/16 - 0s - loss: 0.5071 - accuracy: 0.7489\nEpoch 18/500\n16/16 - 0s - loss: 0.5063 - accuracy: 0.7496\nEpoch 19/500\n16/16 - 0s - loss: 0.5064 - accuracy: 0.7475\nEpoch 20/500\n16/16 - 0s - loss: 0.5056 - accuracy: 0.7481\nEpoch 21/500\n16/16 - 0s - loss: 0.5055 - accuracy: 0.7498\nEpoch 22/500\n16/16 - 0s - loss: 0.5049 - accuracy: 0.7494\nEpoch 23/500\n16/16 - 0s - loss: 0.5038 - accuracy: 0.7507\nEpoch 24/500\n16/16 - 0s - loss: 0.5032 - accuracy: 0.7510\nEpoch 25/500\n16/16 - 0s - loss: 0.5044 - accuracy: 0.7490\nEpoch 26/500\n16/16 - 0s - loss: 0.5034 - accuracy: 0.7514\nEpoch 27/500\n16/16 - 0s - loss: 0.5025 - accuracy: 0.7515\nEpoch 28/500\n16/16 - 0s - loss: 0.5022 - accuracy: 0.7520\nEpoch 29/500\n16/16 - 0s - loss: 0.5014 - accuracy: 0.7528\nEpoch 30/500\n16/16 - 0s - loss: 0.5017 - accuracy: 0.7524\nEpoch 31/500\n16/16 - 0s - loss: 0.5009 - accuracy: 0.7531\nEpoch 32/500\n16/16 - 0s - loss: 0.5020 - accuracy: 0.7514\nEpoch 33/500\n16/16 - 0s - loss: 0.5014 - accuracy: 0.7512\nEpoch 34/500\n16/16 - 0s - loss: 0.5010 - accuracy: 0.7529\nEpoch 35/500\n16/16 - 0s - loss: 0.4999 - accuracy: 0.7541\nEpoch 36/500\n16/16 - 0s - loss: 0.4996 - accuracy: 0.7544\nEpoch 37/500\n16/16 - 0s - loss: 0.4989 - accuracy: 0.7537\nEpoch 38/500\n16/16 - 0s - loss: 0.4989 - accuracy: 0.7532\nEpoch 39/500\n16/16 - 0s - loss: 0.4985 - accuracy: 0.7540\nEpoch 40/500\n16/16 - 0s - loss: 0.4988 - accuracy: 0.7536\nEpoch 41/500\n16/16 - 0s - loss: 0.5004 - accuracy: 0.7530\nEpoch 42/500\n16/16 - 0s - loss: 0.4982 - accuracy: 0.7544\nEpoch 43/500\n16/16 - 0s - loss: 0.4978 - accuracy: 0.7544\nEpoch 44/500\n16/16 - 0s - loss: 0.4977 - accuracy: 0.7540\nEpoch 45/500\n16/16 - 0s - loss: 0.4971 - accuracy: 0.7549\nEpoch 46/500\n16/16 - 0s - loss: 0.4974 - accuracy: 0.7545\nEpoch 47/500\n16/16 - 0s - loss: 0.4965 - accuracy: 0.7552\nEpoch 48/500\n16/16 - 0s - loss: 0.4968 - accuracy: 0.7544\nEpoch 49/500\n16/16 - 0s - loss: 0.4957 - accuracy: 0.7567\nEpoch 50/500\n16/16 - 0s - loss: 0.4963 - accuracy: 0.7560\nEpoch 51/500\n16/16 - 0s - loss: 0.4978 - accuracy: 0.7541\nEpoch 52/500\n16/16 - 0s - loss: 0.4964 - accuracy: 0.7558\nEpoch 53/500\n16/16 - 0s - loss: 0.4954 - accuracy: 0.7551\nEpoch 54/500\n16/16 - 0s - loss: 0.4951 - accuracy: 0.7552\nEpoch 55/500\n16/16 - 0s - loss: 0.4955 - accuracy: 0.7543\nEpoch 56/500\n16/16 - 0s - loss: 0.4960 - accuracy: 0.7557\nEpoch 57/500\n16/16 - 0s - loss: 0.4942 - accuracy: 0.7560\nEpoch 58/500\n16/16 - 0s - loss: 0.4951 - accuracy: 0.7567\nEpoch 59/500\n16/16 - 0s - loss: 0.4955 - accuracy: 0.7542\nEpoch 60/500\n16/16 - 0s - loss: 0.4936 - accuracy: 0.7560\nEpoch 61/500\n16/16 - 0s - loss: 0.4933 - accuracy: 0.7566\nEpoch 62/500\n16/16 - 0s - loss: 0.4933 - accuracy: 0.7576\nEpoch 63/500\n16/16 - 0s - loss: 0.4932 - accuracy: 0.7573\nEpoch 64/500\n16/16 - 0s - loss: 0.4926 - accuracy: 0.7572\nEpoch 65/500\n16/16 - 0s - loss: 0.4929 - accuracy: 0.7566\nEpoch 66/500\n16/16 - 0s - loss: 0.4934 - accuracy: 0.7575\nEpoch 67/500\n16/16 - 0s - loss: 0.4924 - accuracy: 0.7577\nEpoch 68/500\n16/16 - 0s - loss: 0.4949 - accuracy: 0.7566\nEpoch 69/500\n16/16 - 0s - loss: 0.4914 - accuracy: 0.7585\nEpoch 70/500\n16/16 - 0s - loss: 0.4908 - accuracy: 0.7591\nEpoch 71/500\n16/16 - 0s - loss: 0.4911 - accuracy: 0.7576\nEpoch 72/500\n16/16 - 0s - loss: 0.4921 - accuracy: 0.7566\nEpoch 73/500\n16/16 - 0s - loss: 0.4914 - accuracy: 0.7580\nEpoch 74/500\n16/16 - 0s - loss: 0.4902 - accuracy: 0.7591\nEpoch 75/500\n16/16 - 0s - loss: 0.4908 - accuracy: 0.7590\nEpoch 76/500\n16/16 - 0s - loss: 0.4902 - accuracy: 0.7580\nEpoch 77/500\n16/16 - 0s - loss: 0.4905 - accuracy: 0.7586\nEpoch 78/500\n16/16 - 0s - loss: 0.4897 - accuracy: 0.7583\nEpoch 79/500\n16/16 - 0s - loss: 0.4893 - accuracy: 0.7585\nEpoch 80/500\n16/16 - 0s - loss: 0.4888 - accuracy: 0.7586\nEpoch 81/500\n16/16 - 0s - loss: 0.4889 - accuracy: 0.7594\nEpoch 82/500\n16/16 - 0s - loss: 0.4883 - accuracy: 0.7591\nEpoch 83/500\n16/16 - 0s - loss: 0.4895 - accuracy: 0.7600\nEpoch 84/500\n16/16 - 0s - loss: 0.4882 - accuracy: 0.7608\nEpoch 85/500\n16/16 - 0s - loss: 0.4887 - accuracy: 0.7587\nEpoch 86/500\n16/16 - 0s - loss: 0.4874 - accuracy: 0.7609\nEpoch 87/500\n16/16 - 0s - loss: 0.4870 - accuracy: 0.7613\nEpoch 88/500\n16/16 - 0s - loss: 0.4872 - accuracy: 0.7605\nEpoch 89/500\n16/16 - 0s - loss: 0.4873 - accuracy: 0.7600\nEpoch 90/500\n16/16 - 0s - loss: 0.4868 - accuracy: 0.7602\nEpoch 91/500\n16/16 - 0s - loss: 0.4869 - accuracy: 0.7605\nEpoch 92/500\n16/16 - 0s - loss: 0.4865 - accuracy: 0.7612\nEpoch 93/500\n16/16 - 0s - loss: 0.4867 - accuracy: 0.7599\nEpoch 94/500\n16/16 - 0s - loss: 0.4850 - accuracy: 0.7617\nEpoch 95/500\n16/16 - 0s - loss: 0.4860 - accuracy: 0.7610\nEpoch 96/500\n16/16 - 0s - loss: 0.4851 - accuracy: 0.7611\nEpoch 97/500\n16/16 - 0s - loss: 0.4844 - accuracy: 0.7609\nEpoch 98/500\n16/16 - 0s - loss: 0.4847 - accuracy: 0.7619\nEpoch 99/500\n16/16 - 0s - loss: 0.4856 - accuracy: 0.7603\nEpoch 100/500\n16/16 - 0s - loss: 0.4839 - accuracy: 0.7617\nEpoch 101/500\n16/16 - 0s - loss: 0.4836 - accuracy: 0.7622\nEpoch 102/500\n16/16 - 0s - loss: 0.4850 - accuracy: 0.7616\nEpoch 103/500\n16/16 - 0s - loss: 0.4848 - accuracy: 0.7621\nEpoch 104/500\n16/16 - 0s - loss: 0.4836 - accuracy: 0.7618\nEpoch 105/500\n16/16 - 0s - loss: 0.4831 - accuracy: 0.7626\nEpoch 106/500\n16/16 - 0s - loss: 0.4831 - accuracy: 0.7624\nEpoch 107/500\n16/16 - 0s - loss: 0.4859 - accuracy: 0.7615\nEpoch 108/500\n16/16 - 0s - loss: 0.4837 - accuracy: 0.7633\nEpoch 109/500\n16/16 - 0s - loss: 0.4826 - accuracy: 0.7627\nEpoch 110/500\n16/16 - 0s - loss: 0.4822 - accuracy: 0.7633\nEpoch 111/500\n16/16 - 0s - loss: 0.4823 - accuracy: 0.7628\nEpoch 112/500\n16/16 - 0s - loss: 0.4817 - accuracy: 0.7636\nEpoch 113/500\n16/16 - 0s - loss: 0.4811 - accuracy: 0.7636\nEpoch 114/500\n16/16 - 0s - loss: 0.4819 - accuracy: 0.7632\nEpoch 115/500\n16/16 - 0s - loss: 0.4822 - accuracy: 0.7624\nEpoch 116/500\n16/16 - 0s - loss: 0.4848 - accuracy: 0.7611\nEpoch 117/500\n16/16 - 0s - loss: 0.4844 - accuracy: 0.7613\nEpoch 118/500\n16/16 - 0s - loss: 0.4808 - accuracy: 0.7651\nEpoch 119/500\n16/16 - 0s - loss: 0.4805 - accuracy: 0.7635\nEpoch 120/500\n16/16 - 0s - loss: 0.4802 - accuracy: 0.7651\nEpoch 121/500\n16/16 - 0s - loss: 0.4800 - accuracy: 0.7648\nEpoch 122/500\n16/16 - 0s - loss: 0.4794 - accuracy: 0.7647\nEpoch 123/500\n16/16 - 0s - loss: 0.4794 - accuracy: 0.7643\nEpoch 124/500\n16/16 - 0s - loss: 0.4802 - accuracy: 0.7640\nEpoch 125/500\n16/16 - 0s - loss: 0.4833 - accuracy: 0.7629\nEpoch 126/500\n16/16 - 0s - loss: 0.4799 - accuracy: 0.7648\nEpoch 127/500\n16/16 - 0s - loss: 0.4783 - accuracy: 0.7647\nEpoch 128/500\n16/16 - 0s - loss: 0.4780 - accuracy: 0.7665\nEpoch 129/500\n16/16 - 0s - loss: 0.4795 - accuracy: 0.7649\nEpoch 130/500\n16/16 - 0s - loss: 0.4787 - accuracy: 0.7651\nEpoch 131/500\n16/16 - 0s - loss: 0.4782 - accuracy: 0.7664\nEpoch 132/500\n16/16 - 0s - loss: 0.4780 - accuracy: 0.7666\nEpoch 133/500\n16/16 - 0s - loss: 0.4781 - accuracy: 0.7660\nEpoch 134/500\n16/16 - 0s - loss: 0.4793 - accuracy: 0.7670\nEpoch 135/500\n16/16 - 0s - loss: 0.4779 - accuracy: 0.7656\nEpoch 136/500\n16/16 - 0s - loss: 0.4780 - accuracy: 0.7666\nEpoch 137/500\n16/16 - 0s - loss: 0.4767 - accuracy: 0.7670\nEpoch 138/500\n16/16 - 0s - loss: 0.4766 - accuracy: 0.7667\nEpoch 139/500\n16/16 - 0s - loss: 0.4768 - accuracy: 0.7681\nEpoch 140/500\n16/16 - 0s - loss: 0.4772 - accuracy: 0.7672\nEpoch 141/500\n16/16 - 0s - loss: 0.4759 - accuracy: 0.7669\nEpoch 142/500\n16/16 - 0s - loss: 0.4760 - accuracy: 0.7691\nEpoch 143/500\n16/16 - 0s - loss: 0.4764 - accuracy: 0.7681\nEpoch 144/500\n16/16 - 0s - loss: 0.4791 - accuracy: 0.7654\nEpoch 145/500\n16/16 - 0s - loss: 0.4749 - accuracy: 0.7686\nEpoch 146/500\n16/16 - 0s - loss: 0.4755 - accuracy: 0.7678\nEpoch 147/500\n16/16 - 0s - loss: 0.4750 - accuracy: 0.7691\nEpoch 148/500\n16/16 - 0s - loss: 0.4748 - accuracy: 0.7681\nEpoch 149/500\n16/16 - 0s - loss: 0.4746 - accuracy: 0.7696\nEpoch 150/500\n16/16 - 0s - loss: 0.4752 - accuracy: 0.7669\nEpoch 151/500\n16/16 - 0s - loss: 0.4744 - accuracy: 0.7684\nEpoch 152/500\n16/16 - 0s - loss: 0.4738 - accuracy: 0.7705\nEpoch 153/500\n16/16 - 0s - loss: 0.4742 - accuracy: 0.7688\nEpoch 154/500\n16/16 - 0s - loss: 0.4734 - accuracy: 0.7687\nEpoch 155/500\n16/16 - 0s - loss: 0.4726 - accuracy: 0.7699\nEpoch 156/500\n16/16 - 0s - loss: 0.4734 - accuracy: 0.7685\nEpoch 157/500\n16/16 - 0s - loss: 0.4760 - accuracy: 0.7664\nEpoch 158/500\n16/16 - 0s - loss: 0.4738 - accuracy: 0.7680\nEpoch 159/500\n16/16 - 0s - loss: 0.4728 - accuracy: 0.7698\nEpoch 160/500\n16/16 - 0s - loss: 0.4719 - accuracy: 0.7706\nEpoch 161/500\n16/16 - 0s - loss: 0.4718 - accuracy: 0.7699\nEpoch 162/500\n16/16 - 0s - loss: 0.4717 - accuracy: 0.7708\nEpoch 163/500\n16/16 - 0s - loss: 0.4716 - accuracy: 0.7704\nEpoch 164/500\n16/16 - 0s - loss: 0.4717 - accuracy: 0.7698\nEpoch 165/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7708\nEpoch 166/500\n16/16 - 0s - loss: 0.4716 - accuracy: 0.7710\nEpoch 167/500\n16/16 - 0s - loss: 0.4706 - accuracy: 0.7708\nEpoch 168/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7711\nEpoch 169/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7698\nEpoch 170/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7713\nEpoch 171/500\n16/16 - 0s - loss: 0.4708 - accuracy: 0.7709\nEpoch 172/500\n16/16 - 0s - loss: 0.4701 - accuracy: 0.7702\nEpoch 173/500\n16/16 - 0s - loss: 0.4707 - accuracy: 0.7702\nEpoch 174/500\n16/16 - 0s - loss: 0.4697 - accuracy: 0.7716\nEpoch 175/500\n16/16 - 0s - loss: 0.4695 - accuracy: 0.7715\nEpoch 176/500\n16/16 - 0s - loss: 0.4697 - accuracy: 0.7715\nEpoch 177/500\n16/16 - 0s - loss: 0.4723 - accuracy: 0.7698\nEpoch 178/500\n16/16 - 0s - loss: 0.4728 - accuracy: 0.7692\nEpoch 179/500\n16/16 - 0s - loss: 0.4707 - accuracy: 0.7689\nEpoch 180/500\n16/16 - 0s - loss: 0.4694 - accuracy: 0.7716\nEpoch 181/500\n16/16 - 0s - loss: 0.4681 - accuracy: 0.7728\nEpoch 182/500\n16/16 - 0s - loss: 0.4689 - accuracy: 0.7717\nEpoch 183/500\n16/16 - 0s - loss: 0.4682 - accuracy: 0.7731\nEpoch 184/500\n16/16 - 0s - loss: 0.4692 - accuracy: 0.7708\nEpoch 185/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7711\nEpoch 186/500\n16/16 - 0s - loss: 0.4689 - accuracy: 0.7701\nEpoch 187/500\n16/16 - 0s - loss: 0.4686 - accuracy: 0.7726\nEpoch 188/500\n16/16 - 0s - loss: 0.4671 - accuracy: 0.7718\nEpoch 189/500\n16/16 - 0s - loss: 0.4680 - accuracy: 0.7737\nEpoch 190/500\n16/16 - 0s - loss: 0.4688 - accuracy: 0.7724\nEpoch 191/500\n16/16 - 0s - loss: 0.4683 - accuracy: 0.7721\nEpoch 192/500\n16/16 - 0s - loss: 0.4676 - accuracy: 0.7723\nEpoch 193/500\n16/16 - 0s - loss: 0.4677 - accuracy: 0.7731\nEpoch 194/500\n16/16 - 0s - loss: 0.4675 - accuracy: 0.7732\nEpoch 195/500\n16/16 - 0s - loss: 0.4679 - accuracy: 0.7738\nEpoch 196/500\n16/16 - 0s - loss: 0.4675 - accuracy: 0.7742\nEpoch 197/500\n16/16 - 0s - loss: 0.4665 - accuracy: 0.7734\nEpoch 198/500\n16/16 - 0s - loss: 0.4663 - accuracy: 0.7731\nEpoch 199/500\n16/16 - 0s - loss: 0.4656 - accuracy: 0.7749\nEpoch 200/500\n16/16 - 0s - loss: 0.4665 - accuracy: 0.7732\nEpoch 201/500\n16/16 - 0s - loss: 0.4667 - accuracy: 0.7744\nEpoch 202/500\n16/16 - 0s - loss: 0.4663 - accuracy: 0.7738\nEpoch 203/500\n16/16 - 0s - loss: 0.4652 - accuracy: 0.7746\nEpoch 204/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7735\nEpoch 205/500\n16/16 - 0s - loss: 0.4660 - accuracy: 0.7730\nEpoch 206/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7754\nEpoch 207/500\n16/16 - 0s - loss: 0.4650 - accuracy: 0.7746\nEpoch 208/500\n16/16 - 0s - loss: 0.4657 - accuracy: 0.7749\nEpoch 209/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7740\nEpoch 210/500\n16/16 - 0s - loss: 0.4652 - accuracy: 0.7744\nEpoch 211/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7738\nEpoch 212/500\n16/16 - 0s - loss: 0.4650 - accuracy: 0.7744\nEpoch 213/500\n16/16 - 0s - loss: 0.4659 - accuracy: 0.7745\nEpoch 214/500\n16/16 - 0s - loss: 0.4661 - accuracy: 0.7740\nEpoch 215/500\n16/16 - 0s - loss: 0.4641 - accuracy: 0.7743\nEpoch 216/500\n16/16 - 0s - loss: 0.4650 - accuracy: 0.7747\nEpoch 217/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7736\nEpoch 218/500\n16/16 - 0s - loss: 0.4636 - accuracy: 0.7750\nEpoch 219/500\n16/16 - 0s - loss: 0.4653 - accuracy: 0.7734\nEpoch 220/500\n16/16 - 0s - loss: 0.4646 - accuracy: 0.7725\nEpoch 221/500\n16/16 - 0s - loss: 0.4630 - accuracy: 0.7757\nEpoch 222/500\n16/16 - 0s - loss: 0.4627 - accuracy: 0.7749\nEpoch 223/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7753\nEpoch 224/500\n16/16 - 0s - loss: 0.4645 - accuracy: 0.7759\nEpoch 225/500\n16/16 - 0s - loss: 0.4635 - accuracy: 0.7750\nEpoch 226/500\n16/16 - 0s - loss: 0.4655 - accuracy: 0.7742\nEpoch 227/500\n16/16 - 0s - loss: 0.4630 - accuracy: 0.7759\nEpoch 228/500\n16/16 - 0s - loss: 0.4633 - accuracy: 0.7757\nEpoch 229/500\n16/16 - 0s - loss: 0.4645 - accuracy: 0.7746\nEpoch 230/500\n16/16 - 0s - loss: 0.4630 - accuracy: 0.7750\nEpoch 231/500\n16/16 - 0s - loss: 0.4639 - accuracy: 0.7750\nEpoch 232/500\n16/16 - 0s - loss: 0.4634 - accuracy: 0.7739\nEpoch 233/500\n16/16 - 0s - loss: 0.4650 - accuracy: 0.7742\nEpoch 234/500\n16/16 - 0s - loss: 0.4642 - accuracy: 0.7754\nEpoch 235/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7746\nEpoch 236/500\n16/16 - 0s - loss: 0.4639 - accuracy: 0.7755\nEpoch 237/500\n16/16 - 0s - loss: 0.4637 - accuracy: 0.7755\nEpoch 238/500\n16/16 - 0s - loss: 0.4615 - accuracy: 0.7763\nEpoch 239/500\n16/16 - 0s - loss: 0.4627 - accuracy: 0.7772\nEpoch 240/500\n16/16 - 0s - loss: 0.4644 - accuracy: 0.7756\nEpoch 241/500\n16/16 - 0s - loss: 0.4634 - accuracy: 0.7759\nEpoch 242/500\n16/16 - 0s - loss: 0.4620 - accuracy: 0.7761\nEpoch 243/500\n16/16 - 0s - loss: 0.4615 - accuracy: 0.7772\nEpoch 244/500\n16/16 - 0s - loss: 0.4608 - accuracy: 0.7772\nEpoch 245/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7767\nEpoch 246/500\n16/16 - 0s - loss: 0.4619 - accuracy: 0.7766\nEpoch 247/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7770\nEpoch 248/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7793\nEpoch 249/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7779\nEpoch 250/500\n16/16 - 0s - loss: 0.4625 - accuracy: 0.7757\nEpoch 251/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7771\nEpoch 252/500\n16/16 - 0s - loss: 0.4606 - accuracy: 0.7770\nEpoch 253/500\n16/16 - 0s - loss: 0.4603 - accuracy: 0.7770\nEpoch 254/500\n16/16 - 0s - loss: 0.4609 - accuracy: 0.7777\nEpoch 255/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7772\nEpoch 256/500\n16/16 - 0s - loss: 0.4600 - accuracy: 0.7774\nEpoch 257/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7780\nEpoch 258/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7760\nEpoch 259/500\n16/16 - 0s - loss: 0.4613 - accuracy: 0.7764\nEpoch 260/500\n16/16 - 0s - loss: 0.4617 - accuracy: 0.7755\nEpoch 261/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7777\nEpoch 262/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7776\nEpoch 263/500\n16/16 - 0s - loss: 0.4603 - accuracy: 0.7773\nEpoch 264/500\n16/16 - 0s - loss: 0.4598 - accuracy: 0.7781\nEpoch 265/500\n16/16 - 0s - loss: 0.4609 - accuracy: 0.7757\nEpoch 266/500\n16/16 - 0s - loss: 0.4594 - accuracy: 0.7782\nEpoch 267/500\n16/16 - 0s - loss: 0.4592 - accuracy: 0.7776\nEpoch 268/500\n16/16 - 0s - loss: 0.4595 - accuracy: 0.7786\nEpoch 269/500\n16/16 - 0s - loss: 0.4594 - accuracy: 0.7781\nEpoch 270/500\n16/16 - 0s - loss: 0.4591 - accuracy: 0.7785\nEpoch 271/500\n16/16 - 0s - loss: 0.4590 - accuracy: 0.7792\nEpoch 272/500\n16/16 - 0s - loss: 0.4607 - accuracy: 0.7777\nEpoch 273/500\n16/16 - 0s - loss: 0.4625 - accuracy: 0.7772\nEpoch 274/500\n16/16 - 0s - loss: 0.4616 - accuracy: 0.7776\nEpoch 275/500\n16/16 - 0s - loss: 0.4614 - accuracy: 0.7772\nEpoch 276/500\n16/16 - 0s - loss: 0.4604 - accuracy: 0.7778\nEpoch 277/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7768\nEpoch 278/500\n16/16 - 0s - loss: 0.4581 - accuracy: 0.7791\nEpoch 279/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7787\nEpoch 280/500\n16/16 - 0s - loss: 0.4590 - accuracy: 0.7776\nEpoch 281/500\n16/16 - 0s - loss: 0.4586 - accuracy: 0.7782\nEpoch 282/500\n16/16 - 0s - loss: 0.4579 - accuracy: 0.7792\nEpoch 283/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7796\nEpoch 284/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7791\nEpoch 285/500\n16/16 - 0s - loss: 0.4577 - accuracy: 0.7788\nEpoch 286/500\n16/16 - 0s - loss: 0.4581 - accuracy: 0.7792\nEpoch 287/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7773\nEpoch 288/500\n16/16 - 0s - loss: 0.4599 - accuracy: 0.7781\nEpoch 289/500\n16/16 - 0s - loss: 0.4580 - accuracy: 0.7788\nEpoch 290/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7795\nEpoch 291/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7790\nEpoch 292/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7800\nEpoch 293/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7797\nEpoch 294/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7801\nEpoch 295/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7794\nEpoch 296/500\n16/16 - 0s - loss: 0.4581 - accuracy: 0.7783\nEpoch 297/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7798\nEpoch 298/500\n16/16 - 0s - loss: 0.4567 - accuracy: 0.7788\nEpoch 299/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7805\nEpoch 300/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7798\nEpoch 301/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7801\nEpoch 302/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7792\nEpoch 303/500\n16/16 - 0s - loss: 0.4593 - accuracy: 0.7779\nEpoch 304/500\n16/16 - 0s - loss: 0.4592 - accuracy: 0.7788\nEpoch 305/500\n16/16 - 0s - loss: 0.4567 - accuracy: 0.7796\nEpoch 306/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7800\nEpoch 307/500\n16/16 - 0s - loss: 0.4565 - accuracy: 0.7802\nEpoch 308/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7803\nEpoch 309/500\n16/16 - 0s - loss: 0.4566 - accuracy: 0.7799\nEpoch 310/500\n16/16 - 0s - loss: 0.4596 - accuracy: 0.7775\nEpoch 311/500\n16/16 - 0s - loss: 0.4591 - accuracy: 0.7789\nEpoch 312/500\n16/16 - 0s - loss: 0.4561 - accuracy: 0.7809\nEpoch 313/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7800\nEpoch 314/500\n16/16 - 0s - loss: 0.4559 - accuracy: 0.7795\nEpoch 315/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7795\nEpoch 316/500\n16/16 - 0s - loss: 0.4557 - accuracy: 0.7806\nEpoch 317/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7796\nEpoch 318/500\n16/16 - 0s - loss: 0.4557 - accuracy: 0.7808\nEpoch 319/500\n16/16 - 0s - loss: 0.4569 - accuracy: 0.7796\nEpoch 320/500\n16/16 - 0s - loss: 0.4561 - accuracy: 0.7800\nEpoch 321/500\n16/16 - 0s - loss: 0.4577 - accuracy: 0.7787\nEpoch 322/500\n16/16 - 0s - loss: 0.4561 - accuracy: 0.7807\nEpoch 323/500\n16/16 - 0s - loss: 0.4559 - accuracy: 0.7795\nEpoch 324/500\n16/16 - 0s - loss: 0.4585 - accuracy: 0.7778\nEpoch 325/500\n16/16 - 0s - loss: 0.4569 - accuracy: 0.7781\nEpoch 326/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7802\nEpoch 327/500\n16/16 - 0s - loss: 0.4548 - accuracy: 0.7821\nEpoch 328/500\n16/16 - 0s - loss: 0.4555 - accuracy: 0.7809\nEpoch 329/500\n16/16 - 0s - loss: 0.4549 - accuracy: 0.7811\nEpoch 330/500\n16/16 - 0s - loss: 0.4556 - accuracy: 0.7807\nEpoch 331/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7817\nEpoch 332/500\n16/16 - 0s - loss: 0.4553 - accuracy: 0.7808\nEpoch 333/500\n16/16 - 0s - loss: 0.4550 - accuracy: 0.7805\nEpoch 334/500\n16/16 - 0s - loss: 0.4549 - accuracy: 0.7814\nEpoch 335/500\n16/16 - 0s - loss: 0.4555 - accuracy: 0.7806\nEpoch 336/500\n16/16 - 0s - loss: 0.4558 - accuracy: 0.7803\nEpoch 337/500\n16/16 - 0s - loss: 0.4569 - accuracy: 0.7786\nEpoch 338/500\n16/16 - 0s - loss: 0.4545 - accuracy: 0.7807\nEpoch 339/500\n16/16 - 0s - loss: 0.4547 - accuracy: 0.7810\nEpoch 340/500\n16/16 - 0s - loss: 0.4555 - accuracy: 0.7803\nEpoch 341/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7814\nEpoch 342/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7812\nEpoch 343/500\n16/16 - 0s - loss: 0.4541 - accuracy: 0.7820\nEpoch 344/500\n16/16 - 0s - loss: 0.4541 - accuracy: 0.7811\nEpoch 345/500\n16/16 - 0s - loss: 0.4544 - accuracy: 0.7811\nEpoch 346/500\n16/16 - 0s - loss: 0.4542 - accuracy: 0.7810\nEpoch 347/500\n16/16 - 0s - loss: 0.4553 - accuracy: 0.7808\nEpoch 348/500\n16/16 - 0s - loss: 0.4542 - accuracy: 0.7812\nEpoch 349/500\n16/16 - 0s - loss: 0.4542 - accuracy: 0.7812\nEpoch 350/500\n16/16 - 0s - loss: 0.4551 - accuracy: 0.7811\nEpoch 351/500\n16/16 - 0s - loss: 0.4538 - accuracy: 0.7808\nEpoch 352/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7815\nEpoch 353/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7820\nEpoch 354/500\n16/16 - 0s - loss: 0.4528 - accuracy: 0.7823\nEpoch 355/500\n16/16 - 0s - loss: 0.4532 - accuracy: 0.7826\nEpoch 356/500\n16/16 - 0s - loss: 0.4535 - accuracy: 0.7817\nEpoch 357/500\n16/16 - 0s - loss: 0.4538 - accuracy: 0.7815\nEpoch 358/500\n16/16 - 0s - loss: 0.4554 - accuracy: 0.7813\nEpoch 359/500\n16/16 - 0s - loss: 0.4576 - accuracy: 0.7784\nEpoch 360/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7803\nEpoch 361/500\n16/16 - 0s - loss: 0.4546 - accuracy: 0.7808\nEpoch 362/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7813\nEpoch 363/500\n16/16 - 0s - loss: 0.4535 - accuracy: 0.7812\nEpoch 364/500\n16/16 - 0s - loss: 0.4541 - accuracy: 0.7821\nEpoch 365/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7812\nEpoch 366/500\n16/16 - 0s - loss: 0.4524 - accuracy: 0.7823\nEpoch 367/500\n16/16 - 0s - loss: 0.4545 - accuracy: 0.7811\nEpoch 368/500\n16/16 - 0s - loss: 0.4539 - accuracy: 0.7812\nEpoch 369/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7819\nEpoch 370/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7819\nEpoch 371/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7828\nEpoch 372/500\n16/16 - 0s - loss: 0.4557 - accuracy: 0.7806\nEpoch 373/500\n16/16 - 0s - loss: 0.4537 - accuracy: 0.7816\nEpoch 374/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7821\nEpoch 375/500\n16/16 - 0s - loss: 0.4528 - accuracy: 0.7813\nEpoch 376/500\n16/16 - 0s - loss: 0.4539 - accuracy: 0.7810\nEpoch 377/500\n16/16 - 0s - loss: 0.4545 - accuracy: 0.7806\nEpoch 378/500\n16/16 - 0s - loss: 0.4529 - accuracy: 0.7819\nEpoch 379/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7819\nEpoch 380/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7818\nEpoch 381/500\n16/16 - 0s - loss: 0.4522 - accuracy: 0.7826\nEpoch 382/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7820\nEpoch 383/500\n16/16 - 0s - loss: 0.4530 - accuracy: 0.7816\nEpoch 384/500\n16/16 - 0s - loss: 0.4526 - accuracy: 0.7829\nEpoch 385/500\n16/16 - 0s - loss: 0.4515 - accuracy: 0.7836\nEpoch 386/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7823\nEpoch 387/500\n16/16 - 0s - loss: 0.4526 - accuracy: 0.7821\nEpoch 388/500\n16/16 - 0s - loss: 0.4535 - accuracy: 0.7811\nEpoch 389/500\n16/16 - 0s - loss: 0.4517 - accuracy: 0.7824\nEpoch 390/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7823\nEpoch 391/500\n16/16 - 0s - loss: 0.4520 - accuracy: 0.7834\nEpoch 392/500\n16/16 - 0s - loss: 0.4512 - accuracy: 0.7828\nEpoch 393/500\n16/16 - 0s - loss: 0.4519 - accuracy: 0.7834\nEpoch 394/500\n16/16 - 0s - loss: 0.4539 - accuracy: 0.7812\nEpoch 395/500\n16/16 - 0s - loss: 0.4528 - accuracy: 0.7824\nEpoch 396/500\n16/16 - 0s - loss: 0.4517 - accuracy: 0.7833\nEpoch 397/500\n16/16 - 0s - loss: 0.4519 - accuracy: 0.7835\nEpoch 398/500\n16/16 - 0s - loss: 0.4520 - accuracy: 0.7828\nEpoch 399/500\n16/16 - 0s - loss: 0.4514 - accuracy: 0.7821\nEpoch 400/500\n16/16 - 0s - loss: 0.4517 - accuracy: 0.7838\nEpoch 401/500\n16/16 - 0s - loss: 0.4549 - accuracy: 0.7809\nEpoch 402/500\n16/16 - 0s - loss: 0.4530 - accuracy: 0.7818\nEpoch 403/500\n16/16 - 0s - loss: 0.4524 - accuracy: 0.7826\nEpoch 404/500\n16/16 - 0s - loss: 0.4504 - accuracy: 0.7841\nEpoch 405/500\n16/16 - 0s - loss: 0.4512 - accuracy: 0.7823\nEpoch 406/500\n16/16 - 0s - loss: 0.4522 - accuracy: 0.7830\nEpoch 407/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7835\nEpoch 408/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7805\nEpoch 409/500\n16/16 - 0s - loss: 0.4511 - accuracy: 0.7827\nEpoch 410/500\n16/16 - 0s - loss: 0.4498 - accuracy: 0.7831\nEpoch 411/500\n16/16 - 0s - loss: 0.4503 - accuracy: 0.7836\nEpoch 412/500\n16/16 - 0s - loss: 0.4502 - accuracy: 0.7844\nEpoch 413/500\n16/16 - 0s - loss: 0.4510 - accuracy: 0.7828\nEpoch 414/500\n16/16 - 0s - loss: 0.4510 - accuracy: 0.7832\nEpoch 415/500\n16/16 - 0s - loss: 0.4509 - accuracy: 0.7837\nEpoch 416/500\n16/16 - 0s - loss: 0.4512 - accuracy: 0.7832\nEpoch 417/500\n16/16 - 0s - loss: 0.4526 - accuracy: 0.7825\nEpoch 418/500\n16/16 - 0s - loss: 0.4518 - accuracy: 0.7836\nEpoch 419/500\n16/16 - 0s - loss: 0.4497 - accuracy: 0.7842\nEpoch 420/500\n16/16 - 0s - loss: 0.4516 - accuracy: 0.7827\nEpoch 421/500\n16/16 - 0s - loss: 0.4520 - accuracy: 0.7833\nEpoch 422/500\n16/16 - 0s - loss: 0.4511 - accuracy: 0.7823\nEpoch 423/500\n16/16 - 0s - loss: 0.4503 - accuracy: 0.7835\nEpoch 424/500\n16/16 - 0s - loss: 0.4517 - accuracy: 0.7827\nEpoch 425/500\n16/16 - 0s - loss: 0.4513 - accuracy: 0.7830\nEpoch 426/500\n16/16 - 0s - loss: 0.4507 - accuracy: 0.7847\nEpoch 427/500\n16/16 - 0s - loss: 0.4495 - accuracy: 0.7843\nEpoch 428/500\n16/16 - 0s - loss: 0.4493 - accuracy: 0.7848\nEpoch 429/500\n16/16 - 0s - loss: 0.4494 - accuracy: 0.7849\nEpoch 430/500\n16/16 - 0s - loss: 0.4497 - accuracy: 0.7837\nEpoch 431/500\n16/16 - 0s - loss: 0.4500 - accuracy: 0.7847\nEpoch 432/500\n16/16 - 0s - loss: 0.4493 - accuracy: 0.7844\nEpoch 433/500\n16/16 - 0s - loss: 0.4497 - accuracy: 0.7841\nEpoch 434/500\n16/16 - 0s - loss: 0.4502 - accuracy: 0.7840\nEpoch 435/500\n16/16 - 0s - loss: 0.4492 - accuracy: 0.7857\nEpoch 436/500\n16/16 - 0s - loss: 0.4495 - accuracy: 0.7852\nEpoch 437/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7847\nEpoch 438/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7833\nEpoch 439/500\n16/16 - 0s - loss: 0.4498 - accuracy: 0.7838\nEpoch 440/500\n16/16 - 0s - loss: 0.4532 - accuracy: 0.7820\nEpoch 441/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7846\nEpoch 442/500\n16/16 - 0s - loss: 0.4490 - accuracy: 0.7849\nEpoch 443/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7843\nEpoch 444/500\n16/16 - 0s - loss: 0.4498 - accuracy: 0.7857\nEpoch 445/500\n16/16 - 0s - loss: 0.4490 - accuracy: 0.7835\nEpoch 446/500\n16/16 - 0s - loss: 0.4495 - accuracy: 0.7838\nEpoch 447/500\n16/16 - 0s - loss: 0.4493 - accuracy: 0.7856\nEpoch 448/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7841\nEpoch 449/500\n16/16 - 0s - loss: 0.4501 - accuracy: 0.7839\nEpoch 450/500\n16/16 - 0s - loss: 0.4493 - accuracy: 0.7847\nEpoch 451/500\n16/16 - 0s - loss: 0.4482 - accuracy: 0.7849\nEpoch 452/500\n16/16 - 0s - loss: 0.4479 - accuracy: 0.7839\nEpoch 453/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7857\nEpoch 454/500\n16/16 - 0s - loss: 0.4492 - accuracy: 0.7851\nEpoch 455/500\n16/16 - 0s - loss: 0.4510 - accuracy: 0.7848\nEpoch 456/500\n16/16 - 0s - loss: 0.4518 - accuracy: 0.7838\nEpoch 457/500\n16/16 - 0s - loss: 0.4488 - accuracy: 0.7850\nEpoch 458/500\n16/16 - 0s - loss: 0.4509 - accuracy: 0.7848\nEpoch 459/500\n16/16 - 0s - loss: 0.4493 - accuracy: 0.7833\nEpoch 460/500\n16/16 - 0s - loss: 0.4499 - accuracy: 0.7837\nEpoch 461/500\n16/16 - 0s - loss: 0.4501 - accuracy: 0.7828\nEpoch 462/500\n16/16 - 0s - loss: 0.4488 - accuracy: 0.7850\nEpoch 463/500\n16/16 - 0s - loss: 0.4486 - accuracy: 0.7859\nEpoch 464/500\n16/16 - 0s - loss: 0.4492 - accuracy: 0.7847\nEpoch 465/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7847\nEpoch 466/500\n16/16 - 0s - loss: 0.4487 - accuracy: 0.7847\nEpoch 467/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7853\nEpoch 468/500\n16/16 - 0s - loss: 0.4482 - accuracy: 0.7854\nEpoch 469/500\n16/16 - 0s - loss: 0.4478 - accuracy: 0.7845\nEpoch 470/500\n16/16 - 0s - loss: 0.4488 - accuracy: 0.7838\nEpoch 471/500\n16/16 - 0s - loss: 0.4477 - accuracy: 0.7847\nEpoch 472/500\n16/16 - 0s - loss: 0.4480 - accuracy: 0.7856\nEpoch 473/500\n16/16 - 0s - loss: 0.4508 - accuracy: 0.7818\nEpoch 474/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7857\nEpoch 475/500\n16/16 - 0s - loss: 0.4477 - accuracy: 0.7851\nEpoch 476/500\n16/16 - 0s - loss: 0.4489 - accuracy: 0.7847\nEpoch 477/500\n16/16 - 0s - loss: 0.4483 - accuracy: 0.7841\nEpoch 478/500\n16/16 - 0s - loss: 0.4482 - accuracy: 0.7857\nEpoch 479/500\n16/16 - 0s - loss: 0.4483 - accuracy: 0.7846\nEpoch 480/500\n16/16 - 0s - loss: 0.4476 - accuracy: 0.7848\nEpoch 481/500\n16/16 - 0s - loss: 0.4481 - accuracy: 0.7846\nEpoch 482/500\n16/16 - 0s - loss: 0.4494 - accuracy: 0.7847\nEpoch 483/500\n16/16 - 0s - loss: 0.4478 - accuracy: 0.7836\nEpoch 484/500\n16/16 - 0s - loss: 0.4476 - accuracy: 0.7853\nEpoch 485/500\n16/16 - 0s - loss: 0.4469 - accuracy: 0.7849\nEpoch 486/500\n16/16 - 0s - loss: 0.4467 - accuracy: 0.7871\nEpoch 487/500\n16/16 - 0s - loss: 0.4475 - accuracy: 0.7844\nEpoch 488/500\n16/16 - 0s - loss: 0.4476 - accuracy: 0.7868\nEpoch 489/500\n16/16 - 0s - loss: 0.4475 - accuracy: 0.7859\nEpoch 490/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7856\nEpoch 491/500\n16/16 - 0s - loss: 0.4475 - accuracy: 0.7855\nEpoch 492/500\n16/16 - 0s - loss: 0.4472 - accuracy: 0.7849\nEpoch 493/500\n16/16 - 0s - loss: 0.4475 - accuracy: 0.7853\nEpoch 494/500\n16/16 - 0s - loss: 0.4473 - accuracy: 0.7859\nEpoch 495/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7846\nEpoch 496/500\n16/16 - 0s - loss: 0.4468 - accuracy: 0.7858\nEpoch 497/500\n16/16 - 0s - loss: 0.4472 - accuracy: 0.7852\nEpoch 498/500\n16/16 - 0s - loss: 0.4484 - accuracy: 0.7858\nEpoch 499/500\n16/16 - 0s - loss: 0.4461 - accuracy: 0.7861\nEpoch 500/500\n16/16 - 0s - loss: 0.4472 - accuracy: 0.7845\n"}]},{"cell_type":"markdown","metadata":{"id":"S_ZowJis0crC","colab_type":"text"},"source":["## Validation of the Model"]},{"cell_type":"code","metadata":{"tags":[],"id":"wcN4ybhW0crD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593197040987,"user_tz":300,"elapsed":822,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"3e76aedc-db46-478e-a813-3a00c4339c85"},"source":["#Evaluate the Model using the testing data\n","#Compare Model performace between training and testing data\n","model_loss_train, model_accuracy_train = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n","model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n","\n","print(f\"TRAINING DATA --> Loss: {model_loss_train}, Accuracy: {model_accuracy_train}\")    \n","print(f\"TESTING DATA --> Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"964/964 - 1s - loss: 0.4454 - accuracy: 0.7881\n322/322 - 0s - loss: 0.4818 - accuracy: 0.7699\nTRAINING DATA --> Loss: 0.4454091191291809, Accuracy: 0.7880891561508179\nTESTING DATA --> Loss: 0.48179200291633606, Accuracy: 0.7698744535446167\n"}]},{"cell_type":"markdown","metadata":{"id":"5iOzWcF50crF","colab_type":"text"},"source":["## Saving the Trained Model"]},{"cell_type":"code","metadata":{"id":"13uMQTlH0crG","colab_type":"code","colab":{}},"source":["# Save the model\n","model.save(\"../Models/h5/schorus&speech.h5\")"],"execution_count":15,"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"},"orig_nbformat":2,"kernelspec":{"name":"python38364bitvenvvenv54c3120af49c4f098fcd2d81e62b322e","display_name":"Python 3.8.3 64-bit ('venv': venv)"},"colab":{"name":"model_v2_Grecia2.ipynb","provenance":[{"file_id":"11wI5Qfi-s_wzKnroqXDrvjKOaF8fJka3","timestamp":1593196456960}]}},"nbformat":4,"nbformat_minor":0}
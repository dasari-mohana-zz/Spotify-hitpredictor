{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1593195154984,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "NcG0IxjY0cqN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1593195258189,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "KvMq-KpR0cqS"
   },
   "outputs": [],
   "source": [
    "# Define working directory\n",
    "os.chdir(r\"C:\\Users\\Cristina Bardan\\Desktop\\Repositories\\FinalProject-Spotify\\Original_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2168,
     "status": "ok",
     "timestamp": 1593195263589,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "a-ewU33W0cqV",
    "outputId": "8ba3883a-b147-4ff4-8222-b8dba28181ae"
   },
   "outputs": [],
   "source": [
    "# Use glob to match the pattern ‘csv’\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "# Combine all files in the list and export as CSV\n",
    "df = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1593195265828,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "eKjuVkuQ0cqZ",
    "outputId": "df03010b-e8c2-4b2b-c626-a3e31011898b"
   },
   "outputs": [],
   "source": [
    "df2 = df.drop(['track', 'artist', 'uri'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1593195268295,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "JqlHQ-yC0cqf",
    "outputId": "d2482f13-7bf8-4a39-c38b-9232402800f3"
   },
   "outputs": [],
   "source": [
    "#Validation of correlation between variables\n",
    "import numpy as np \n",
    "df3=df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1593195270316,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "5QtG0P4q0cqj"
   },
   "outputs": [],
   "source": [
    "#1. Sin key - crih\n",
    "#2. Sin Tempo - chris  / - purvi\n",
    "#3. Sin speechiness / purvi  -grecia\n",
    "#4. Sin chorus_hit  / grecia \n",
    "#5. Sin key, Tempo, speechiness, chorus_hit- heidy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1593195792804,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "2bkdcEPG1ibv"
   },
   "outputs": [],
   "source": [
    "# Sin tempo & speechiness\n",
    "data = df2\n",
    "X = data[['danceability', 'energy','key', 'loudness','mode', 'acousticness', 'instrumentalness', 'liveness','valence', 'duration_ms', 'time_signature','chorus_hit', 'sections']]  \n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1593195806764,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "jY2Jscy60cqq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABiuRgdQ0cqt"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1593195809079,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "hfEdBDfb0cqu",
    "outputId": "911efcc3-99ac-4918-84b9-2d5aa84691b4"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.78947368, 0.52283395, 0.81818182, ..., 0.8       , 0.19905999,\n        0.06508876],\n       [0.54048583, 0.83094117, 0.81818182, ..., 0.8       , 0.21633373,\n        0.04142012],\n       [0.5       , 0.66588373, 0.81818182, ..., 0.8       , 0.20480589,\n        0.03550296],\n       ...,\n       [0.57692308, 0.36777999, 0.81818182, ..., 0.8       , 0.15844718,\n        0.09467456],\n       [0.41902834, 0.16070793, 0.63636364, ..., 0.8       , 0.200772  ,\n        0.04733728],\n       [0.29554656, 0.24873856, 0.81818182, ..., 0.6       , 0.12021911,\n        0.06508876]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#Scale features (X) using MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler(feature_range=(0,1)).fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test) \n",
    "\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uy2UDESH0cqy"
   },
   "source": [
    "One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1593195813074,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "2bgX_eKc0cqz",
    "outputId": "3afa952d-bc15-4952-c8c2-8c312c2d0a34"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 1.],\n       [1., 0.],\n       [0., 1.],\n       ...,\n       [0., 1.],\n       [0., 1.],\n       [1., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#One-hot encode output labels (y)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "y_train_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdxnMFS40cq2"
   },
   "source": [
    "## Creating and defining our Deep Learning Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1593195865739,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "Vengxhzv0cq3"
   },
   "outputs": [],
   "source": [
    "#Create a sequential model\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential() \n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 13  \n",
    "\n",
    "#Create hidden layers\n",
    "model.add(Dense(units=14,activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(units=120,activation='relu'))\n",
    "model.add(Dense(units=80,activation='relu'))\n",
    "\n",
    "#Create output layer\n",
    "number_classes = 2\n",
    "model.add(Dense(units=number_classes, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-z2bcd60cq5"
   },
   "source": [
    "Number of Hidden Nodes \n",
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=The%20number%20of%20hidden%20neurons,size%20of%20the%20input%20layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1593195868686,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "e68kh-j-0cq6",
    "outputId": "a0c6ff91-e482-4074-86ec-c4d5dc809a54",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 14)                196       \n_________________________________________________________________\ndense_1 (Dense)              (None, 120)               1800      \n_________________________________________________________________\ndense_2 (Dense)              (None, 80)                9680      \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 162       \n=================================================================\nTotal params: 11,838\nTrainable params: 11,838\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "#Model Summary\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1593195871538,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "wJTml5b60cq9"
   },
   "outputs": [],
   "source": [
    "#Compile the Model\n",
    "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4H8OtKeZ0cq_"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135077,
     "status": "ok",
     "timestamp": 1593196007986,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "-CFXztyU0crA",
    "outputId": "8117547b-6034-4c47-e5c3-40103be12fcf",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/500\n16/16 - 0s - loss: 0.6740 - accuracy: 0.5975\nEpoch 2/500\n16/16 - 0s - loss: 0.6168 - accuracy: 0.6710\nEpoch 3/500\n16/16 - 0s - loss: 0.5598 - accuracy: 0.7080\nEpoch 4/500\n16/16 - 0s - loss: 0.5378 - accuracy: 0.7259\nEpoch 5/500\n16/16 - 0s - loss: 0.5298 - accuracy: 0.7309\nEpoch 6/500\n16/16 - 0s - loss: 0.5238 - accuracy: 0.7362\nEpoch 7/500\n16/16 - 0s - loss: 0.5183 - accuracy: 0.7388\nEpoch 8/500\n16/16 - 0s - loss: 0.5170 - accuracy: 0.7411\nEpoch 9/500\n16/16 - 0s - loss: 0.5133 - accuracy: 0.7426\nEpoch 10/500\n16/16 - 0s - loss: 0.5115 - accuracy: 0.7433\nEpoch 11/500\n16/16 - 0s - loss: 0.5095 - accuracy: 0.7444\nEpoch 12/500\n16/16 - 0s - loss: 0.5067 - accuracy: 0.7472\nEpoch 13/500\n16/16 - 0s - loss: 0.5064 - accuracy: 0.7463\nEpoch 14/500\n16/16 - 0s - loss: 0.5045 - accuracy: 0.7491\nEpoch 15/500\n16/16 - 0s - loss: 0.5048 - accuracy: 0.7493\nEpoch 16/500\n16/16 - 0s - loss: 0.5042 - accuracy: 0.7495\nEpoch 17/500\n16/16 - 0s - loss: 0.5023 - accuracy: 0.7504\nEpoch 18/500\n16/16 - 0s - loss: 0.5016 - accuracy: 0.7502\nEpoch 19/500\n16/16 - 0s - loss: 0.5033 - accuracy: 0.7494\nEpoch 20/500\n16/16 - 0s - loss: 0.5007 - accuracy: 0.7525\nEpoch 21/500\n16/16 - 0s - loss: 0.5006 - accuracy: 0.7527\nEpoch 22/500\n16/16 - 0s - loss: 0.4992 - accuracy: 0.7542\nEpoch 23/500\n16/16 - 0s - loss: 0.4992 - accuracy: 0.7529\nEpoch 24/500\n16/16 - 0s - loss: 0.4978 - accuracy: 0.7545\nEpoch 25/500\n16/16 - 0s - loss: 0.4980 - accuracy: 0.7554\nEpoch 26/500\n16/16 - 0s - loss: 0.4989 - accuracy: 0.7531\nEpoch 27/500\n16/16 - 0s - loss: 0.4966 - accuracy: 0.7543\nEpoch 28/500\n16/16 - 0s - loss: 0.4962 - accuracy: 0.7553\nEpoch 29/500\n16/16 - 0s - loss: 0.4974 - accuracy: 0.7540\nEpoch 30/500\n16/16 - 0s - loss: 0.4954 - accuracy: 0.7568\nEpoch 31/500\n16/16 - 0s - loss: 0.4965 - accuracy: 0.7552\nEpoch 32/500\n16/16 - 0s - loss: 0.4950 - accuracy: 0.7557\nEpoch 33/500\n16/16 - 0s - loss: 0.4956 - accuracy: 0.7558\nEpoch 34/500\n16/16 - 0s - loss: 0.4936 - accuracy: 0.7566\nEpoch 35/500\n16/16 - 0s - loss: 0.4930 - accuracy: 0.7572\nEpoch 36/500\n16/16 - 0s - loss: 0.4939 - accuracy: 0.7571\nEpoch 37/500\n16/16 - 0s - loss: 0.4938 - accuracy: 0.7579\nEpoch 38/500\n16/16 - 0s - loss: 0.4932 - accuracy: 0.7564\nEpoch 39/500\n16/16 - 0s - loss: 0.4929 - accuracy: 0.7580\nEpoch 40/500\n16/16 - 0s - loss: 0.4924 - accuracy: 0.7579\nEpoch 41/500\n16/16 - 0s - loss: 0.4924 - accuracy: 0.7593\nEpoch 42/500\n16/16 - 0s - loss: 0.4936 - accuracy: 0.7563\nEpoch 43/500\n16/16 - 0s - loss: 0.4918 - accuracy: 0.7575\nEpoch 44/500\n16/16 - 0s - loss: 0.4906 - accuracy: 0.7610\nEpoch 45/500\n16/16 - 0s - loss: 0.4917 - accuracy: 0.7585\nEpoch 46/500\n16/16 - 0s - loss: 0.4928 - accuracy: 0.7573\nEpoch 47/500\n16/16 - 0s - loss: 0.4900 - accuracy: 0.7590\nEpoch 48/500\n16/16 - 0s - loss: 0.4907 - accuracy: 0.7587\nEpoch 49/500\n16/16 - 0s - loss: 0.4904 - accuracy: 0.7608\nEpoch 50/500\n16/16 - 0s - loss: 0.4903 - accuracy: 0.7605\nEpoch 51/500\n16/16 - 0s - loss: 0.4895 - accuracy: 0.7603\nEpoch 52/500\n16/16 - 0s - loss: 0.4910 - accuracy: 0.7585\nEpoch 53/500\n16/16 - 0s - loss: 0.4896 - accuracy: 0.7605\nEpoch 54/500\n16/16 - 0s - loss: 0.4911 - accuracy: 0.7582\nEpoch 55/500\n16/16 - 0s - loss: 0.4886 - accuracy: 0.7607\nEpoch 56/500\n16/16 - 0s - loss: 0.4888 - accuracy: 0.7612\nEpoch 57/500\n16/16 - 0s - loss: 0.4878 - accuracy: 0.7617\nEpoch 58/500\n16/16 - 0s - loss: 0.4883 - accuracy: 0.7620\nEpoch 59/500\n16/16 - 0s - loss: 0.4889 - accuracy: 0.7607\nEpoch 60/500\n16/16 - 0s - loss: 0.4879 - accuracy: 0.7619\nEpoch 61/500\n16/16 - 0s - loss: 0.4873 - accuracy: 0.7608\nEpoch 62/500\n16/16 - 0s - loss: 0.4880 - accuracy: 0.7617\nEpoch 63/500\n16/16 - 0s - loss: 0.4872 - accuracy: 0.7614\nEpoch 64/500\n16/16 - 0s - loss: 0.4872 - accuracy: 0.7616\nEpoch 65/500\n16/16 - 0s - loss: 0.4898 - accuracy: 0.7584\nEpoch 66/500\n16/16 - 0s - loss: 0.4887 - accuracy: 0.7600\nEpoch 67/500\n16/16 - 0s - loss: 0.4864 - accuracy: 0.7623\nEpoch 68/500\n16/16 - 0s - loss: 0.4866 - accuracy: 0.7605\nEpoch 69/500\n16/16 - 0s - loss: 0.4889 - accuracy: 0.7598\nEpoch 70/500\n16/16 - 0s - loss: 0.4872 - accuracy: 0.7624\nEpoch 71/500\n16/16 - 0s - loss: 0.4853 - accuracy: 0.7634\nEpoch 72/500\n16/16 - 0s - loss: 0.4853 - accuracy: 0.7630\nEpoch 73/500\n16/16 - 0s - loss: 0.4872 - accuracy: 0.7607\nEpoch 74/500\n16/16 - 0s - loss: 0.4852 - accuracy: 0.7627\nEpoch 75/500\n16/16 - 0s - loss: 0.4884 - accuracy: 0.7607\nEpoch 76/500\n16/16 - 0s - loss: 0.4845 - accuracy: 0.7624\nEpoch 77/500\n16/16 - 0s - loss: 0.4853 - accuracy: 0.7644\nEpoch 78/500\n16/16 - 0s - loss: 0.4859 - accuracy: 0.7618\nEpoch 79/500\n16/16 - 0s - loss: 0.4837 - accuracy: 0.7631\nEpoch 80/500\n16/16 - 0s - loss: 0.4848 - accuracy: 0.7630\nEpoch 81/500\n16/16 - 0s - loss: 0.4843 - accuracy: 0.7636\nEpoch 82/500\n16/16 - 0s - loss: 0.4852 - accuracy: 0.7637\nEpoch 83/500\n16/16 - 0s - loss: 0.4837 - accuracy: 0.7633\nEpoch 84/500\n16/16 - 0s - loss: 0.4829 - accuracy: 0.7640\nEpoch 85/500\n16/16 - 0s - loss: 0.4847 - accuracy: 0.7635\nEpoch 86/500\n16/16 - 0s - loss: 0.4833 - accuracy: 0.7632\nEpoch 87/500\n16/16 - 0s - loss: 0.4833 - accuracy: 0.7640\nEpoch 88/500\n16/16 - 0s - loss: 0.4824 - accuracy: 0.7647\nEpoch 89/500\n16/16 - 0s - loss: 0.4848 - accuracy: 0.7633\nEpoch 90/500\n16/16 - 0s - loss: 0.4819 - accuracy: 0.7640\nEpoch 91/500\n16/16 - 0s - loss: 0.4828 - accuracy: 0.7635\nEpoch 92/500\n16/16 - 0s - loss: 0.4820 - accuracy: 0.7643\nEpoch 93/500\n16/16 - 0s - loss: 0.4826 - accuracy: 0.7641\nEpoch 94/500\n16/16 - 0s - loss: 0.4840 - accuracy: 0.7638\nEpoch 95/500\n16/16 - 0s - loss: 0.4829 - accuracy: 0.7635\nEpoch 96/500\n16/16 - 0s - loss: 0.4810 - accuracy: 0.7645\nEpoch 97/500\n16/16 - 0s - loss: 0.4827 - accuracy: 0.7631\nEpoch 98/500\n16/16 - 0s - loss: 0.4826 - accuracy: 0.7636\nEpoch 99/500\n16/16 - 0s - loss: 0.4811 - accuracy: 0.7653\nEpoch 100/500\n16/16 - 0s - loss: 0.4828 - accuracy: 0.7636\nEpoch 101/500\n16/16 - 0s - loss: 0.4803 - accuracy: 0.7654\nEpoch 102/500\n16/16 - 0s - loss: 0.4804 - accuracy: 0.7650\nEpoch 103/500\n16/16 - 0s - loss: 0.4808 - accuracy: 0.7654\nEpoch 104/500\n16/16 - 0s - loss: 0.4810 - accuracy: 0.7634\nEpoch 105/500\n16/16 - 0s - loss: 0.4804 - accuracy: 0.7650\nEpoch 106/500\n16/16 - 0s - loss: 0.4827 - accuracy: 0.7635\nEpoch 107/500\n16/16 - 0s - loss: 0.4805 - accuracy: 0.7654\nEpoch 108/500\n16/16 - 0s - loss: 0.4818 - accuracy: 0.7637\nEpoch 109/500\n16/16 - 0s - loss: 0.4791 - accuracy: 0.7665\nEpoch 110/500\n16/16 - 0s - loss: 0.4798 - accuracy: 0.7655\nEpoch 111/500\n16/16 - 0s - loss: 0.4792 - accuracy: 0.7651\nEpoch 112/500\n16/16 - 0s - loss: 0.4810 - accuracy: 0.7652\nEpoch 113/500\n16/16 - 0s - loss: 0.4804 - accuracy: 0.7644\nEpoch 114/500\n16/16 - 0s - loss: 0.4788 - accuracy: 0.7655\nEpoch 115/500\n16/16 - 0s - loss: 0.4790 - accuracy: 0.7668\nEpoch 116/500\n16/16 - 0s - loss: 0.4787 - accuracy: 0.7664\nEpoch 117/500\n16/16 - 0s - loss: 0.4805 - accuracy: 0.7651\nEpoch 118/500\n16/16 - 0s - loss: 0.4796 - accuracy: 0.7662\nEpoch 119/500\n16/16 - 0s - loss: 0.4793 - accuracy: 0.7658\nEpoch 120/500\n16/16 - 0s - loss: 0.4808 - accuracy: 0.7648\nEpoch 121/500\n16/16 - 0s - loss: 0.4786 - accuracy: 0.7659\nEpoch 122/500\n16/16 - 0s - loss: 0.4786 - accuracy: 0.7656\nEpoch 123/500\n16/16 - 0s - loss: 0.4787 - accuracy: 0.7653\nEpoch 124/500\n16/16 - 0s - loss: 0.4772 - accuracy: 0.7668\nEpoch 125/500\n16/16 - 0s - loss: 0.4778 - accuracy: 0.7677\nEpoch 126/500\n16/16 - 0s - loss: 0.4792 - accuracy: 0.7653\nEpoch 127/500\n16/16 - 0s - loss: 0.4781 - accuracy: 0.7665\nEpoch 128/500\n16/16 - 0s - loss: 0.4780 - accuracy: 0.7672\nEpoch 129/500\n16/16 - 0s - loss: 0.4763 - accuracy: 0.7681\nEpoch 130/500\n16/16 - 0s - loss: 0.4769 - accuracy: 0.7674\nEpoch 131/500\n16/16 - 0s - loss: 0.4793 - accuracy: 0.7647\nEpoch 132/500\n16/16 - 0s - loss: 0.4773 - accuracy: 0.7664\nEpoch 133/500\n16/16 - 0s - loss: 0.4770 - accuracy: 0.7676\nEpoch 134/500\n16/16 - 0s - loss: 0.4781 - accuracy: 0.7665\nEpoch 135/500\n16/16 - 0s - loss: 0.4759 - accuracy: 0.7687\nEpoch 136/500\n16/16 - 0s - loss: 0.4767 - accuracy: 0.7679\nEpoch 137/500\n16/16 - 0s - loss: 0.4769 - accuracy: 0.7670\nEpoch 138/500\n16/16 - 0s - loss: 0.4756 - accuracy: 0.7681\nEpoch 139/500\n16/16 - 0s - loss: 0.4755 - accuracy: 0.7682\nEpoch 140/500\n16/16 - 0s - loss: 0.4780 - accuracy: 0.7666\nEpoch 141/500\n16/16 - 0s - loss: 0.4770 - accuracy: 0.7674\nEpoch 142/500\n16/16 - 0s - loss: 0.4758 - accuracy: 0.7685\nEpoch 143/500\n16/16 - 0s - loss: 0.4748 - accuracy: 0.7680\nEpoch 144/500\n16/16 - 0s - loss: 0.4755 - accuracy: 0.7682\nEpoch 145/500\n16/16 - 0s - loss: 0.4768 - accuracy: 0.7664\nEpoch 146/500\n16/16 - 0s - loss: 0.4746 - accuracy: 0.7677\nEpoch 147/500\n16/16 - 0s - loss: 0.4752 - accuracy: 0.7685\nEpoch 148/500\n16/16 - 0s - loss: 0.4748 - accuracy: 0.7686\nEpoch 149/500\n16/16 - 0s - loss: 0.4745 - accuracy: 0.7679\nEpoch 150/500\n16/16 - 0s - loss: 0.4746 - accuracy: 0.7681\nEpoch 151/500\n16/16 - 0s - loss: 0.4746 - accuracy: 0.7690\nEpoch 152/500\n16/16 - 0s - loss: 0.4750 - accuracy: 0.7687\nEpoch 153/500\n16/16 - 0s - loss: 0.4739 - accuracy: 0.7694\nEpoch 154/500\n16/16 - 0s - loss: 0.4767 - accuracy: 0.7669\nEpoch 155/500\n16/16 - 0s - loss: 0.4734 - accuracy: 0.7690\nEpoch 156/500\n16/16 - 0s - loss: 0.4732 - accuracy: 0.7686\nEpoch 157/500\n16/16 - 0s - loss: 0.4760 - accuracy: 0.7681\nEpoch 158/500\n16/16 - 0s - loss: 0.4735 - accuracy: 0.7690\nEpoch 159/500\n16/16 - 0s - loss: 0.4737 - accuracy: 0.7695\nEpoch 160/500\n16/16 - 0s - loss: 0.4757 - accuracy: 0.7669\nEpoch 161/500\n16/16 - 0s - loss: 0.4730 - accuracy: 0.7692\nEpoch 162/500\n16/16 - 0s - loss: 0.4730 - accuracy: 0.7699\nEpoch 163/500\n16/16 - 0s - loss: 0.4737 - accuracy: 0.7691\nEpoch 164/500\n16/16 - 0s - loss: 0.4726 - accuracy: 0.7702\nEpoch 165/500\n16/16 - 0s - loss: 0.4736 - accuracy: 0.7697\nEpoch 166/500\n16/16 - 0s - loss: 0.4759 - accuracy: 0.7663\nEpoch 167/500\n16/16 - 0s - loss: 0.4723 - accuracy: 0.7694\nEpoch 168/500\n16/16 - 0s - loss: 0.4713 - accuracy: 0.7706\nEpoch 169/500\n16/16 - 0s - loss: 0.4733 - accuracy: 0.7699\nEpoch 170/500\n16/16 - 0s - loss: 0.4715 - accuracy: 0.7703\nEpoch 171/500\n16/16 - 0s - loss: 0.4719 - accuracy: 0.7702\nEpoch 172/500\n16/16 - 0s - loss: 0.4714 - accuracy: 0.7697\nEpoch 173/500\n16/16 - 0s - loss: 0.4724 - accuracy: 0.7700\nEpoch 174/500\n16/16 - 0s - loss: 0.4715 - accuracy: 0.7710\nEpoch 175/500\n16/16 - 0s - loss: 0.4720 - accuracy: 0.7698\nEpoch 176/500\n16/16 - 0s - loss: 0.4741 - accuracy: 0.7685\nEpoch 177/500\n16/16 - 0s - loss: 0.4723 - accuracy: 0.7694\nEpoch 178/500\n16/16 - 0s - loss: 0.4705 - accuracy: 0.7703\nEpoch 179/500\n16/16 - 0s - loss: 0.4733 - accuracy: 0.7697\nEpoch 180/500\n16/16 - 0s - loss: 0.4713 - accuracy: 0.7712\nEpoch 181/500\n16/16 - 0s - loss: 0.4706 - accuracy: 0.7714\nEpoch 182/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7713\nEpoch 183/500\n16/16 - 0s - loss: 0.4702 - accuracy: 0.7718\nEpoch 184/500\n16/16 - 0s - loss: 0.4710 - accuracy: 0.7704\nEpoch 185/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7718\nEpoch 186/500\n16/16 - 0s - loss: 0.4717 - accuracy: 0.7698\nEpoch 187/500\n16/16 - 0s - loss: 0.4715 - accuracy: 0.7697\nEpoch 188/500\n16/16 - 0s - loss: 0.4703 - accuracy: 0.7699\nEpoch 189/500\n16/16 - 0s - loss: 0.4690 - accuracy: 0.7722\nEpoch 190/500\n16/16 - 0s - loss: 0.4704 - accuracy: 0.7699\nEpoch 191/500\n16/16 - 0s - loss: 0.4701 - accuracy: 0.7711\nEpoch 192/500\n16/16 - 0s - loss: 0.4688 - accuracy: 0.7723\nEpoch 193/500\n16/16 - 0s - loss: 0.4685 - accuracy: 0.7730\nEpoch 194/500\n16/16 - 0s - loss: 0.4692 - accuracy: 0.7714\nEpoch 195/500\n16/16 - 0s - loss: 0.4688 - accuracy: 0.7707\nEpoch 196/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7710\nEpoch 197/500\n16/16 - 0s - loss: 0.4690 - accuracy: 0.7714\nEpoch 198/500\n16/16 - 0s - loss: 0.4694 - accuracy: 0.7726\nEpoch 199/500\n16/16 - 0s - loss: 0.4682 - accuracy: 0.7712\nEpoch 200/500\n16/16 - 0s - loss: 0.4680 - accuracy: 0.7720\nEpoch 201/500\n16/16 - 0s - loss: 0.4677 - accuracy: 0.7724\nEpoch 202/500\n16/16 - 0s - loss: 0.4689 - accuracy: 0.7711\nEpoch 203/500\n16/16 - 0s - loss: 0.4708 - accuracy: 0.7704\nEpoch 204/500\n16/16 - 0s - loss: 0.4690 - accuracy: 0.7726\nEpoch 205/500\n16/16 - 0s - loss: 0.4689 - accuracy: 0.7721\nEpoch 206/500\n16/16 - 0s - loss: 0.4696 - accuracy: 0.7703\nEpoch 207/500\n16/16 - 0s - loss: 0.4677 - accuracy: 0.7734\nEpoch 208/500\n16/16 - 0s - loss: 0.4686 - accuracy: 0.7730\nEpoch 209/500\n16/16 - 0s - loss: 0.4683 - accuracy: 0.7706\nEpoch 210/500\n16/16 - 0s - loss: 0.4667 - accuracy: 0.7735\nEpoch 211/500\n16/16 - 0s - loss: 0.4668 - accuracy: 0.7725\nEpoch 212/500\n16/16 - 0s - loss: 0.4671 - accuracy: 0.7731\nEpoch 213/500\n16/16 - 0s - loss: 0.4668 - accuracy: 0.7723\nEpoch 214/500\n16/16 - 0s - loss: 0.4668 - accuracy: 0.7729\nEpoch 215/500\n16/16 - 0s - loss: 0.4680 - accuracy: 0.7724\nEpoch 216/500\n16/16 - 0s - loss: 0.4668 - accuracy: 0.7731\nEpoch 217/500\n16/16 - 0s - loss: 0.4666 - accuracy: 0.7716\nEpoch 218/500\n16/16 - 0s - loss: 0.4660 - accuracy: 0.7735\nEpoch 219/500\n16/16 - 0s - loss: 0.4673 - accuracy: 0.7722\nEpoch 220/500\n16/16 - 0s - loss: 0.4659 - accuracy: 0.7741\nEpoch 221/500\n16/16 - 0s - loss: 0.4676 - accuracy: 0.7714\nEpoch 222/500\n16/16 - 0s - loss: 0.4660 - accuracy: 0.7736\nEpoch 223/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7743\nEpoch 224/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7738\nEpoch 225/500\n16/16 - 0s - loss: 0.4681 - accuracy: 0.7709\nEpoch 226/500\n16/16 - 0s - loss: 0.4665 - accuracy: 0.7733\nEpoch 227/500\n16/16 - 0s - loss: 0.4655 - accuracy: 0.7732\nEpoch 228/500\n16/16 - 0s - loss: 0.4659 - accuracy: 0.7735\nEpoch 229/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7740\nEpoch 230/500\n16/16 - 0s - loss: 0.4652 - accuracy: 0.7733\nEpoch 231/500\n16/16 - 0s - loss: 0.4653 - accuracy: 0.7730\nEpoch 232/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7735\nEpoch 233/500\n16/16 - 0s - loss: 0.4643 - accuracy: 0.7749\nEpoch 234/500\n16/16 - 0s - loss: 0.4646 - accuracy: 0.7734\nEpoch 235/500\n16/16 - 0s - loss: 0.4659 - accuracy: 0.7740\nEpoch 236/500\n16/16 - 0s - loss: 0.4639 - accuracy: 0.7756\nEpoch 237/500\n16/16 - 0s - loss: 0.4648 - accuracy: 0.7750\nEpoch 238/500\n16/16 - 0s - loss: 0.4648 - accuracy: 0.7745\nEpoch 239/500\n16/16 - 0s - loss: 0.4659 - accuracy: 0.7730\nEpoch 240/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7736\nEpoch 241/500\n16/16 - 0s - loss: 0.4637 - accuracy: 0.7755\nEpoch 242/500\n16/16 - 0s - loss: 0.4635 - accuracy: 0.7754\nEpoch 243/500\n16/16 - 0s - loss: 0.4641 - accuracy: 0.7747\nEpoch 244/500\n16/16 - 0s - loss: 0.4636 - accuracy: 0.7747\nEpoch 245/500\n16/16 - 0s - loss: 0.4643 - accuracy: 0.7748\nEpoch 246/500\n16/16 - 0s - loss: 0.4639 - accuracy: 0.7739\nEpoch 247/500\n16/16 - 0s - loss: 0.4642 - accuracy: 0.7736\nEpoch 248/500\n16/16 - 0s - loss: 0.4627 - accuracy: 0.7743\nEpoch 249/500\n16/16 - 0s - loss: 0.4663 - accuracy: 0.7722\nEpoch 250/500\n16/16 - 0s - loss: 0.4623 - accuracy: 0.7750\nEpoch 251/500\n16/16 - 0s - loss: 0.4629 - accuracy: 0.7749\nEpoch 252/500\n16/16 - 0s - loss: 0.4630 - accuracy: 0.7753\nEpoch 253/500\n16/16 - 0s - loss: 0.4620 - accuracy: 0.7750\nEpoch 254/500\n16/16 - 0s - loss: 0.4626 - accuracy: 0.7757\nEpoch 255/500\n16/16 - 0s - loss: 0.4626 - accuracy: 0.7760\nEpoch 256/500\n16/16 - 0s - loss: 0.4624 - accuracy: 0.7768\nEpoch 257/500\n16/16 - 0s - loss: 0.4629 - accuracy: 0.7751\nEpoch 258/500\n16/16 - 0s - loss: 0.4622 - accuracy: 0.7754\nEpoch 259/500\n16/16 - 0s - loss: 0.4632 - accuracy: 0.7754\nEpoch 260/500\n16/16 - 0s - loss: 0.4633 - accuracy: 0.7757\nEpoch 261/500\n16/16 - 0s - loss: 0.4615 - accuracy: 0.7760\nEpoch 262/500\n16/16 - 0s - loss: 0.4623 - accuracy: 0.7761\nEpoch 263/500\n16/16 - 0s - loss: 0.4609 - accuracy: 0.7758\nEpoch 264/500\n16/16 - 0s - loss: 0.4622 - accuracy: 0.7748\nEpoch 265/500\n16/16 - 0s - loss: 0.4621 - accuracy: 0.7757\nEpoch 266/500\n16/16 - 0s - loss: 0.4611 - accuracy: 0.7766\nEpoch 267/500\n16/16 - 0s - loss: 0.4608 - accuracy: 0.7754\nEpoch 268/500\n16/16 - 0s - loss: 0.4642 - accuracy: 0.7744\nEpoch 269/500\n16/16 - 0s - loss: 0.4607 - accuracy: 0.7758\nEpoch 270/500\n16/16 - 0s - loss: 0.4604 - accuracy: 0.7774\nEpoch 271/500\n16/16 - 0s - loss: 0.4614 - accuracy: 0.7763\nEpoch 272/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7764\nEpoch 273/500\n16/16 - 0s - loss: 0.4619 - accuracy: 0.7765\nEpoch 274/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7767\nEpoch 275/500\n16/16 - 0s - loss: 0.4618 - accuracy: 0.7759\nEpoch 276/500\n16/16 - 0s - loss: 0.4611 - accuracy: 0.7761\nEpoch 277/500\n16/16 - 0s - loss: 0.4607 - accuracy: 0.7773\nEpoch 278/500\n16/16 - 0s - loss: 0.4602 - accuracy: 0.7763\nEpoch 279/500\n16/16 - 0s - loss: 0.4634 - accuracy: 0.7761\nEpoch 280/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7772\nEpoch 281/500\n16/16 - 0s - loss: 0.4606 - accuracy: 0.7771\nEpoch 282/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7760\nEpoch 283/500\n16/16 - 0s - loss: 0.4604 - accuracy: 0.7763\nEpoch 284/500\n16/16 - 0s - loss: 0.4606 - accuracy: 0.7767\nEpoch 285/500\n16/16 - 0s - loss: 0.4616 - accuracy: 0.7741\nEpoch 286/500\n16/16 - 0s - loss: 0.4596 - accuracy: 0.7775\nEpoch 287/500\n16/16 - 0s - loss: 0.4602 - accuracy: 0.7762\nEpoch 288/500\n16/16 - 0s - loss: 0.4584 - accuracy: 0.7769\nEpoch 289/500\n16/16 - 0s - loss: 0.4584 - accuracy: 0.7772\nEpoch 290/500\n16/16 - 0s - loss: 0.4588 - accuracy: 0.7788\nEpoch 291/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7742\nEpoch 292/500\n16/16 - 0s - loss: 0.4606 - accuracy: 0.7761\nEpoch 293/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7781\nEpoch 294/500\n16/16 - 0s - loss: 0.4600 - accuracy: 0.7765\nEpoch 295/500\n16/16 - 0s - loss: 0.4589 - accuracy: 0.7775\nEpoch 296/500\n16/16 - 0s - loss: 0.4579 - accuracy: 0.7783\nEpoch 297/500\n16/16 - 0s - loss: 0.4587 - accuracy: 0.7781\nEpoch 298/500\n16/16 - 0s - loss: 0.4597 - accuracy: 0.7777\nEpoch 299/500\n16/16 - 0s - loss: 0.4584 - accuracy: 0.7783\nEpoch 300/500\n16/16 - 0s - loss: 0.4595 - accuracy: 0.7777\nEpoch 301/500\n16/16 - 0s - loss: 0.4575 - accuracy: 0.7778\nEpoch 302/500\n16/16 - 0s - loss: 0.4577 - accuracy: 0.7790\nEpoch 303/500\n16/16 - 0s - loss: 0.4581 - accuracy: 0.7779\nEpoch 304/500\n16/16 - 0s - loss: 0.4580 - accuracy: 0.7779\nEpoch 305/500\n16/16 - 0s - loss: 0.4574 - accuracy: 0.7782\nEpoch 306/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7791\nEpoch 307/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7776\nEpoch 308/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7783\nEpoch 309/500\n16/16 - 0s - loss: 0.4567 - accuracy: 0.7787\nEpoch 310/500\n16/16 - 0s - loss: 0.4610 - accuracy: 0.7763\nEpoch 311/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7782\nEpoch 312/500\n16/16 - 0s - loss: 0.4586 - accuracy: 0.7783\nEpoch 313/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7786\nEpoch 314/500\n16/16 - 0s - loss: 0.4564 - accuracy: 0.7786\nEpoch 315/500\n16/16 - 0s - loss: 0.4565 - accuracy: 0.7789\nEpoch 316/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7791\nEpoch 317/500\n16/16 - 0s - loss: 0.4585 - accuracy: 0.7778\nEpoch 318/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7786\nEpoch 319/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7784\nEpoch 320/500\n16/16 - 0s - loss: 0.4565 - accuracy: 0.7786\nEpoch 321/500\n16/16 - 0s - loss: 0.4562 - accuracy: 0.7792\nEpoch 322/500\n16/16 - 0s - loss: 0.4564 - accuracy: 0.7778\nEpoch 323/500\n16/16 - 0s - loss: 0.4551 - accuracy: 0.7800\nEpoch 324/500\n16/16 - 0s - loss: 0.4562 - accuracy: 0.7793\nEpoch 325/500\n16/16 - 0s - loss: 0.4576 - accuracy: 0.7781\nEpoch 326/500\n16/16 - 0s - loss: 0.4556 - accuracy: 0.7803\nEpoch 327/500\n16/16 - 0s - loss: 0.4558 - accuracy: 0.7801\nEpoch 328/500\n16/16 - 0s - loss: 0.4558 - accuracy: 0.7803\nEpoch 329/500\n16/16 - 0s - loss: 0.4562 - accuracy: 0.7802\nEpoch 330/500\n16/16 - 0s - loss: 0.4553 - accuracy: 0.7803\nEpoch 331/500\n16/16 - 0s - loss: 0.4553 - accuracy: 0.7806\nEpoch 332/500\n16/16 - 0s - loss: 0.4546 - accuracy: 0.7814\nEpoch 333/500\n16/16 - 0s - loss: 0.4565 - accuracy: 0.7795\nEpoch 334/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7810\nEpoch 335/500\n16/16 - 0s - loss: 0.4544 - accuracy: 0.7809\nEpoch 336/500\n16/16 - 0s - loss: 0.4545 - accuracy: 0.7788\nEpoch 337/500\n16/16 - 0s - loss: 0.4566 - accuracy: 0.7799\nEpoch 338/500\n16/16 - 0s - loss: 0.4553 - accuracy: 0.7797\nEpoch 339/500\n16/16 - 0s - loss: 0.4546 - accuracy: 0.7804\nEpoch 340/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7790\nEpoch 341/500\n16/16 - 0s - loss: 0.4550 - accuracy: 0.7796\nEpoch 342/500\n16/16 - 0s - loss: 0.4554 - accuracy: 0.7800\nEpoch 343/500\n16/16 - 0s - loss: 0.4540 - accuracy: 0.7802\nEpoch 344/500\n16/16 - 0s - loss: 0.4541 - accuracy: 0.7799\nEpoch 345/500\n16/16 - 0s - loss: 0.4545 - accuracy: 0.7793\nEpoch 346/500\n16/16 - 0s - loss: 0.4537 - accuracy: 0.7803\nEpoch 347/500\n16/16 - 0s - loss: 0.4545 - accuracy: 0.7799\nEpoch 348/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7820\nEpoch 349/500\n16/16 - 0s - loss: 0.4532 - accuracy: 0.7809\nEpoch 350/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7811\nEpoch 351/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7812\nEpoch 352/500\n16/16 - 0s - loss: 0.4537 - accuracy: 0.7799\nEpoch 353/500\n16/16 - 0s - loss: 0.4533 - accuracy: 0.7818\nEpoch 354/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7816\nEpoch 355/500\n16/16 - 0s - loss: 0.4546 - accuracy: 0.7807\nEpoch 356/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7818\nEpoch 357/500\n16/16 - 0s - loss: 0.4520 - accuracy: 0.7816\nEpoch 358/500\n16/16 - 0s - loss: 0.4528 - accuracy: 0.7826\nEpoch 359/500\n16/16 - 0s - loss: 0.4540 - accuracy: 0.7809\nEpoch 360/500\n16/16 - 0s - loss: 0.4517 - accuracy: 0.7827\nEpoch 361/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7807\nEpoch 362/500\n16/16 - 0s - loss: 0.4552 - accuracy: 0.7797\nEpoch 363/500\n16/16 - 0s - loss: 0.4528 - accuracy: 0.7809\nEpoch 364/500\n16/16 - 0s - loss: 0.4524 - accuracy: 0.7828\nEpoch 365/500\n16/16 - 0s - loss: 0.4518 - accuracy: 0.7813\nEpoch 366/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7819\nEpoch 367/500\n16/16 - 0s - loss: 0.4516 - accuracy: 0.7820\nEpoch 368/500\n16/16 - 0s - loss: 0.4530 - accuracy: 0.7802\nEpoch 369/500\n16/16 - 0s - loss: 0.4524 - accuracy: 0.7815\nEpoch 370/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7807\nEpoch 371/500\n16/16 - 0s - loss: 0.4516 - accuracy: 0.7816\nEpoch 372/500\n16/16 - 0s - loss: 0.4511 - accuracy: 0.7822\nEpoch 373/500\n16/16 - 0s - loss: 0.4513 - accuracy: 0.7824\nEpoch 374/500\n16/16 - 0s - loss: 0.4528 - accuracy: 0.7807\nEpoch 375/500\n16/16 - 0s - loss: 0.4512 - accuracy: 0.7823\nEpoch 376/500\n16/16 - 0s - loss: 0.4511 - accuracy: 0.7821\nEpoch 377/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7803\nEpoch 378/500\n16/16 - 0s - loss: 0.4511 - accuracy: 0.7818\nEpoch 379/500\n16/16 - 0s - loss: 0.4513 - accuracy: 0.7813\nEpoch 380/500\n16/16 - 0s - loss: 0.4510 - accuracy: 0.7821\nEpoch 381/500\n16/16 - 0s - loss: 0.4511 - accuracy: 0.7828\nEpoch 382/500\n16/16 - 0s - loss: 0.4504 - accuracy: 0.7817\nEpoch 383/500\n16/16 - 0s - loss: 0.4503 - accuracy: 0.7839\nEpoch 384/500\n16/16 - 0s - loss: 0.4507 - accuracy: 0.7819\nEpoch 385/500\n16/16 - 0s - loss: 0.4503 - accuracy: 0.7834\nEpoch 386/500\n16/16 - 0s - loss: 0.4499 - accuracy: 0.7827\nEpoch 387/500\n16/16 - 0s - loss: 0.4513 - accuracy: 0.7816\nEpoch 388/500\n16/16 - 0s - loss: 0.4500 - accuracy: 0.7828\nEpoch 389/500\n16/16 - 0s - loss: 0.4494 - accuracy: 0.7838\nEpoch 390/500\n16/16 - 0s - loss: 0.4505 - accuracy: 0.7825\nEpoch 391/500\n16/16 - 0s - loss: 0.4491 - accuracy: 0.7833\nEpoch 392/500\n16/16 - 0s - loss: 0.4502 - accuracy: 0.7835\nEpoch 393/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7826\nEpoch 394/500\n16/16 - 0s - loss: 0.4493 - accuracy: 0.7832\nEpoch 395/500\n16/16 - 0s - loss: 0.4500 - accuracy: 0.7823\nEpoch 396/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7834\nEpoch 397/500\n16/16 - 0s - loss: 0.4486 - accuracy: 0.7838\nEpoch 398/500\n16/16 - 0s - loss: 0.4504 - accuracy: 0.7830\nEpoch 399/500\n16/16 - 0s - loss: 0.4495 - accuracy: 0.7832\nEpoch 400/500\n16/16 - 0s - loss: 0.4486 - accuracy: 0.7826\nEpoch 401/500\n16/16 - 0s - loss: 0.4486 - accuracy: 0.7843\nEpoch 402/500\n16/16 - 0s - loss: 0.4501 - accuracy: 0.7840\nEpoch 403/500\n16/16 - 0s - loss: 0.4490 - accuracy: 0.7843\nEpoch 404/500\n16/16 - 0s - loss: 0.4490 - accuracy: 0.7833\nEpoch 405/500\n16/16 - 0s - loss: 0.4486 - accuracy: 0.7848\nEpoch 406/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7822\nEpoch 407/500\n16/16 - 0s - loss: 0.4483 - accuracy: 0.7846\nEpoch 408/500\n16/16 - 0s - loss: 0.4486 - accuracy: 0.7847\nEpoch 409/500\n16/16 - 0s - loss: 0.4474 - accuracy: 0.7840\nEpoch 410/500\n16/16 - 0s - loss: 0.4496 - accuracy: 0.7847\nEpoch 411/500\n16/16 - 0s - loss: 0.4482 - accuracy: 0.7837\nEpoch 412/500\n16/16 - 0s - loss: 0.4476 - accuracy: 0.7844\nEpoch 413/500\n16/16 - 0s - loss: 0.4476 - accuracy: 0.7847\nEpoch 414/500\n16/16 - 0s - loss: 0.4489 - accuracy: 0.7842\nEpoch 415/500\n16/16 - 0s - loss: 0.4473 - accuracy: 0.7850\nEpoch 416/500\n16/16 - 0s - loss: 0.4474 - accuracy: 0.7850\nEpoch 417/500\n16/16 - 0s - loss: 0.4475 - accuracy: 0.7854\nEpoch 418/500\n16/16 - 0s - loss: 0.4481 - accuracy: 0.7843\nEpoch 419/500\n16/16 - 0s - loss: 0.4480 - accuracy: 0.7857\nEpoch 420/500\n16/16 - 0s - loss: 0.4492 - accuracy: 0.7845\nEpoch 421/500\n16/16 - 0s - loss: 0.4475 - accuracy: 0.7842\nEpoch 422/500\n16/16 - 0s - loss: 0.4465 - accuracy: 0.7852\nEpoch 423/500\n16/16 - 0s - loss: 0.4464 - accuracy: 0.7848\nEpoch 424/500\n16/16 - 0s - loss: 0.4470 - accuracy: 0.7849\nEpoch 425/500\n16/16 - 0s - loss: 0.4470 - accuracy: 0.7846\nEpoch 426/500\n16/16 - 0s - loss: 0.4468 - accuracy: 0.7843\nEpoch 427/500\n16/16 - 0s - loss: 0.4462 - accuracy: 0.7859\nEpoch 428/500\n16/16 - 0s - loss: 0.4478 - accuracy: 0.7831\nEpoch 429/500\n16/16 - 0s - loss: 0.4482 - accuracy: 0.7837\nEpoch 430/500\n16/16 - 0s - loss: 0.4461 - accuracy: 0.7848\nEpoch 431/500\n16/16 - 0s - loss: 0.4477 - accuracy: 0.7846\nEpoch 432/500\n16/16 - 0s - loss: 0.4462 - accuracy: 0.7856\nEpoch 433/500\n16/16 - 0s - loss: 0.4458 - accuracy: 0.7861\nEpoch 434/500\n16/16 - 0s - loss: 0.4464 - accuracy: 0.7850\nEpoch 435/500\n16/16 - 0s - loss: 0.4495 - accuracy: 0.7850\nEpoch 436/500\n16/16 - 0s - loss: 0.4459 - accuracy: 0.7857\nEpoch 437/500\n16/16 - 0s - loss: 0.4469 - accuracy: 0.7841\nEpoch 438/500\n16/16 - 0s - loss: 0.4467 - accuracy: 0.7850\nEpoch 439/500\n16/16 - 0s - loss: 0.4467 - accuracy: 0.7867\nEpoch 440/500\n16/16 - 0s - loss: 0.4456 - accuracy: 0.7870\nEpoch 441/500\n16/16 - 0s - loss: 0.4462 - accuracy: 0.7858\nEpoch 442/500\n16/16 - 0s - loss: 0.4458 - accuracy: 0.7857\nEpoch 443/500\n16/16 - 0s - loss: 0.4459 - accuracy: 0.7847\nEpoch 444/500\n16/16 - 0s - loss: 0.4447 - accuracy: 0.7862\nEpoch 445/500\n16/16 - 0s - loss: 0.4462 - accuracy: 0.7865\nEpoch 446/500\n16/16 - 0s - loss: 0.4455 - accuracy: 0.7857\nEpoch 447/500\n16/16 - 0s - loss: 0.4448 - accuracy: 0.7870\nEpoch 448/500\n16/16 - 0s - loss: 0.4449 - accuracy: 0.7872\nEpoch 449/500\n16/16 - 0s - loss: 0.4466 - accuracy: 0.7845\nEpoch 450/500\n16/16 - 0s - loss: 0.4451 - accuracy: 0.7870\nEpoch 451/500\n16/16 - 0s - loss: 0.4455 - accuracy: 0.7864\nEpoch 452/500\n16/16 - 0s - loss: 0.4446 - accuracy: 0.7866\nEpoch 453/500\n16/16 - 0s - loss: 0.4437 - accuracy: 0.7886\nEpoch 454/500\n16/16 - 0s - loss: 0.4453 - accuracy: 0.7867\nEpoch 455/500\n16/16 - 0s - loss: 0.4439 - accuracy: 0.7869\nEpoch 456/500\n16/16 - 0s - loss: 0.4456 - accuracy: 0.7863\nEpoch 457/500\n16/16 - 0s - loss: 0.4445 - accuracy: 0.7867\nEpoch 458/500\n16/16 - 0s - loss: 0.4446 - accuracy: 0.7859\nEpoch 459/500\n16/16 - 0s - loss: 0.4436 - accuracy: 0.7883\nEpoch 460/500\n16/16 - 0s - loss: 0.4439 - accuracy: 0.7878\nEpoch 461/500\n16/16 - 0s - loss: 0.4447 - accuracy: 0.7873\nEpoch 462/500\n16/16 - 0s - loss: 0.4435 - accuracy: 0.7878\nEpoch 463/500\n16/16 - 0s - loss: 0.4450 - accuracy: 0.7863\nEpoch 464/500\n16/16 - 0s - loss: 0.4431 - accuracy: 0.7881\nEpoch 465/500\n16/16 - 0s - loss: 0.4438 - accuracy: 0.7872\nEpoch 466/500\n16/16 - 0s - loss: 0.4430 - accuracy: 0.7885\nEpoch 467/500\n16/16 - 0s - loss: 0.4451 - accuracy: 0.7865\nEpoch 468/500\n16/16 - 0s - loss: 0.4445 - accuracy: 0.7868\nEpoch 469/500\n16/16 - 0s - loss: 0.4435 - accuracy: 0.7870\nEpoch 470/500\n16/16 - 0s - loss: 0.4433 - accuracy: 0.7876\nEpoch 471/500\n16/16 - 0s - loss: 0.4437 - accuracy: 0.7871\nEpoch 472/500\n16/16 - 0s - loss: 0.4422 - accuracy: 0.7889\nEpoch 473/500\n16/16 - 0s - loss: 0.4425 - accuracy: 0.7873\nEpoch 474/500\n16/16 - 0s - loss: 0.4430 - accuracy: 0.7865\nEpoch 475/500\n16/16 - 0s - loss: 0.4423 - accuracy: 0.7876\nEpoch 476/500\n16/16 - 0s - loss: 0.4432 - accuracy: 0.7885\nEpoch 477/500\n16/16 - 0s - loss: 0.4420 - accuracy: 0.7880\nEpoch 478/500\n16/16 - 0s - loss: 0.4422 - accuracy: 0.7889\nEpoch 479/500\n16/16 - 0s - loss: 0.4438 - accuracy: 0.7873\nEpoch 480/500\n16/16 - 0s - loss: 0.4422 - accuracy: 0.7876\nEpoch 481/500\n16/16 - 0s - loss: 0.4434 - accuracy: 0.7877\nEpoch 482/500\n16/16 - 0s - loss: 0.4437 - accuracy: 0.7865\nEpoch 483/500\n16/16 - 0s - loss: 0.4418 - accuracy: 0.7887\nEpoch 484/500\n16/16 - 0s - loss: 0.4423 - accuracy: 0.7881\nEpoch 485/500\n16/16 - 0s - loss: 0.4417 - accuracy: 0.7888\nEpoch 486/500\n16/16 - 0s - loss: 0.4427 - accuracy: 0.7883\nEpoch 487/500\n16/16 - 0s - loss: 0.4421 - accuracy: 0.7877\nEpoch 488/500\n16/16 - 0s - loss: 0.4425 - accuracy: 0.7883\nEpoch 489/500\n16/16 - 0s - loss: 0.4442 - accuracy: 0.7872\nEpoch 490/500\n16/16 - 0s - loss: 0.4417 - accuracy: 0.7896\nEpoch 491/500\n16/16 - 0s - loss: 0.4410 - accuracy: 0.7895\nEpoch 492/500\n16/16 - 0s - loss: 0.4415 - accuracy: 0.7888\nEpoch 493/500\n16/16 - 0s - loss: 0.4410 - accuracy: 0.7898\nEpoch 494/500\n16/16 - 0s - loss: 0.4411 - accuracy: 0.7900\nEpoch 495/500\n16/16 - 0s - loss: 0.4414 - accuracy: 0.7892\nEpoch 496/500\n16/16 - 0s - loss: 0.4436 - accuracy: 0.7857\nEpoch 497/500\n16/16 - 0s - loss: 0.4417 - accuracy: 0.7882\nEpoch 498/500\n16/16 - 0s - loss: 0.4407 - accuracy: 0.7888\nEpoch 499/500\n16/16 - 0s - loss: 0.4423 - accuracy: 0.7886\nEpoch 500/500\n16/16 - 0s - loss: 0.4409 - accuracy: 0.7889\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1ac8aa87a90>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#Training the Model\n",
    "import tensorflow as tf\n",
    "\n",
    "model.fit(X_train_scaled,y_train_categorical,epochs=500, batch_size=2000, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_ZowJis0crC"
   },
   "source": [
    "## Validation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1593196025137,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "wcN4ybhW0crD",
    "outputId": "3acad8f1-ef7b-4f57-f9ca-5e50185535bc",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "322/322 - 0s - loss: 0.4964 - accuracy: 0.7618\nLoss: 0.49638205766677856, Accuracy: 0.7617982029914856\n"
    }
   ],
   "source": [
    "#Evaluate the Model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "    \n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5iOzWcF50crF"
   },
   "source": [
    "## Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1593196165263,
     "user": {
      "displayName": "Grecia Villarreal",
      "photoUrl": "",
      "userId": "04417287800158359907"
     },
     "user_tz": 300
    },
    "id": "13uMQTlH0crG"
   },
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# Define working directory\n",
    "#os.chdir(r\"C:\\Users\\hguzm\\Documents\\000. Personal\\Bootcamp\\Proyectos\\FinalProject-Spotify\")\n",
    "#model.save(\"spotify_DeepLearning_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dYRUJMs0crJ"
   },
   "source": [
    "## Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1beJ-J6k0crJ"
   },
   "outputs": [],
   "source": [
    "# Load the model  \n",
    "from tensorflow.keras.models import load_model\n",
    "# Define working directory\n",
    "os.chdir(r\"C:\\Users\\hguzm\\Documents\\000. Personal\\Bootcamp\\Proyectos\\FinalProject-Spotify\")\n",
    "model = load_model(\"spotify_DeepLearning_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35f9x40J0crM",
    "outputId": "12d0cef2-1e2d-4ca4-f734-8c96881be198",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csQ0sXEf0crO"
   },
   "source": [
    "## Validation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5WF280V0crP",
    "outputId": "4f6c83c2-fd70-427a-e249-9f928abb553b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Evaluate the Model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "    \n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdBgyOh60crR"
   },
   "outputs": [],
   "source": [
    "# #Making Predictions with new data\n",
    "# new_data = np.array([[0.2, 0.3, 0.4,0.2, 0.3, 0.4,0.2, 0.3, 0.4,0.2, 0.3, 0.4,0.2, 0.3, 0.4]])  # AQUI IRIA INFORMACIÓN DEL API\n",
    "# print(f\"Predicted class: {model.predict_classes(new_data)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of model_v2.ipynb",
   "provenance": [
    {
     "file_id": "11wI5Qfi-s_wzKnroqXDrvjKOaF8fJka3",
     "timestamp": 1593196456960
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38364bitvenvvenv54c3120af49c4f098fcd2d81e62b322e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
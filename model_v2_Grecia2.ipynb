{"cells":[{"cell_type":"code","metadata":{"id":"91pdNomL0doM","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1593196734381,"user_tz":300,"elapsed":134315,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"b1d9233f-9955-45b0-9cd5-29f9b917b941"},"source":["# from google.colab import files\n","# uploaded = files.upload()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcG0IxjY0cqN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196908132,"user_tz":300,"elapsed":528,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["import os\n","import glob\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvMq-KpR0cqS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196908988,"user_tz":300,"elapsed":307,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["# Define working directory\n","os.chdir(r\"C:\\Users\\hguzm\\Documents\\000. Personal\\Bootcamp\\Proyectos\\FinalProject-Spotify\\Original_data\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-ewU33W0cqV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1593196911081,"user_tz":300,"elapsed":1331,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"d879194f-8c82-4f01-b1e4-c37861cc10b0"},"source":["# Use glob to match the pattern ‘csv’\n","extension = 'csv'\n","all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n","\n","# Combine all files in the list and export as CSV\n","df = pd.concat([pd.read_csv(f) for f in all_filenames ])\n","df.reset_index(drop=True, inplace=True)\n","\n","# #export to csv\n","# df.to_csv( \"spotify_data.csv\", index=False, encoding='utf-8-sig')\n","df.head(5)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":"                      track             artist  \\\n0                 Lucky Man  Montgomery Gentry   \n1            On The Hotline       Pretty Ricky   \n2        Clouds Of Dementia         Candlemass   \n3  Heavy Metal, Raise Hell!      Zwartketterij   \n4           I Got A Feelin'   Billy Currington   \n\n                                    uri  danceability  energy  key  loudness  \\\n0  spotify:track:4GiXBCUF7H6YfNQsnBRIzl         0.578   0.471    4    -7.270   \n1  spotify:track:1zyqZONW985Cs4osz9wlsu         0.704   0.854   10    -5.477   \n2  spotify:track:6cHZf7RbxXCKwEkgAZT4mY         0.162   0.836    9    -3.009   \n3  spotify:track:2IjBPp2vMeX7LggzRN3iSX         0.188   0.994    4    -3.745   \n4  spotify:track:1tF370eYXUcWwkIvaq3IGz         0.630   0.764    2    -4.353   \n\n   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n0     1       0.0289      0.368000           0.00000     0.159    0.532   \n1     0       0.1830      0.018500           0.00000     0.148    0.688   \n2     1       0.0473      0.000111           0.00457     0.174    0.300   \n3     1       0.1660      0.000007           0.07840     0.192    0.333   \n4     1       0.0275      0.363000           0.00000     0.125    0.631   \n\n     tempo  duration_ms  time_signature  chorus_hit  sections  target  \n0  133.061       196707               4    30.88059        13       1  \n1   92.988       242587               4    41.51106        10       1  \n2   86.964       338893               4    65.32887        13       0  \n3  148.440       255667               4    58.59528         9       0  \n4  112.098       193760               4    22.62384        10       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track</th>\n      <th>artist</th>\n      <th>uri</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n      <th>time_signature</th>\n      <th>chorus_hit</th>\n      <th>sections</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Lucky Man</td>\n      <td>Montgomery Gentry</td>\n      <td>spotify:track:4GiXBCUF7H6YfNQsnBRIzl</td>\n      <td>0.578</td>\n      <td>0.471</td>\n      <td>4</td>\n      <td>-7.270</td>\n      <td>1</td>\n      <td>0.0289</td>\n      <td>0.368000</td>\n      <td>0.00000</td>\n      <td>0.159</td>\n      <td>0.532</td>\n      <td>133.061</td>\n      <td>196707</td>\n      <td>4</td>\n      <td>30.88059</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>On The Hotline</td>\n      <td>Pretty Ricky</td>\n      <td>spotify:track:1zyqZONW985Cs4osz9wlsu</td>\n      <td>0.704</td>\n      <td>0.854</td>\n      <td>10</td>\n      <td>-5.477</td>\n      <td>0</td>\n      <td>0.1830</td>\n      <td>0.018500</td>\n      <td>0.00000</td>\n      <td>0.148</td>\n      <td>0.688</td>\n      <td>92.988</td>\n      <td>242587</td>\n      <td>4</td>\n      <td>41.51106</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Clouds Of Dementia</td>\n      <td>Candlemass</td>\n      <td>spotify:track:6cHZf7RbxXCKwEkgAZT4mY</td>\n      <td>0.162</td>\n      <td>0.836</td>\n      <td>9</td>\n      <td>-3.009</td>\n      <td>1</td>\n      <td>0.0473</td>\n      <td>0.000111</td>\n      <td>0.00457</td>\n      <td>0.174</td>\n      <td>0.300</td>\n      <td>86.964</td>\n      <td>338893</td>\n      <td>4</td>\n      <td>65.32887</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Heavy Metal, Raise Hell!</td>\n      <td>Zwartketterij</td>\n      <td>spotify:track:2IjBPp2vMeX7LggzRN3iSX</td>\n      <td>0.188</td>\n      <td>0.994</td>\n      <td>4</td>\n      <td>-3.745</td>\n      <td>1</td>\n      <td>0.1660</td>\n      <td>0.000007</td>\n      <td>0.07840</td>\n      <td>0.192</td>\n      <td>0.333</td>\n      <td>148.440</td>\n      <td>255667</td>\n      <td>4</td>\n      <td>58.59528</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>I Got A Feelin'</td>\n      <td>Billy Currington</td>\n      <td>spotify:track:1tF370eYXUcWwkIvaq3IGz</td>\n      <td>0.630</td>\n      <td>0.764</td>\n      <td>2</td>\n      <td>-4.353</td>\n      <td>1</td>\n      <td>0.0275</td>\n      <td>0.363000</td>\n      <td>0.00000</td>\n      <td>0.125</td>\n      <td>0.631</td>\n      <td>112.098</td>\n      <td>193760</td>\n      <td>4</td>\n      <td>22.62384</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"eKjuVkuQ0cqZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1593196913124,"user_tz":300,"elapsed":321,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"17e77d62-f709-4494-83a5-c18f75520286"},"source":["df2 = df.drop(['track', 'artist', 'uri'], axis=1)\n","df2.head(2)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":"   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n0         0.578   0.471    4    -7.270     1       0.0289        0.3680   \n1         0.704   0.854   10    -5.477     0       0.1830        0.0185   \n\n   instrumentalness  liveness  valence    tempo  duration_ms  time_signature  \\\n0               0.0     0.159    0.532  133.061       196707               4   \n1               0.0     0.148    0.688   92.988       242587               4   \n\n   chorus_hit  sections  target  \n0    30.88059        13       1  \n1    41.51106        10       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n      <th>time_signature</th>\n      <th>chorus_hit</th>\n      <th>sections</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.578</td>\n      <td>0.471</td>\n      <td>4</td>\n      <td>-7.270</td>\n      <td>1</td>\n      <td>0.0289</td>\n      <td>0.3680</td>\n      <td>0.0</td>\n      <td>0.159</td>\n      <td>0.532</td>\n      <td>133.061</td>\n      <td>196707</td>\n      <td>4</td>\n      <td>30.88059</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.704</td>\n      <td>0.854</td>\n      <td>10</td>\n      <td>-5.477</td>\n      <td>0</td>\n      <td>0.1830</td>\n      <td>0.0185</td>\n      <td>0.0</td>\n      <td>0.148</td>\n      <td>0.688</td>\n      <td>92.988</td>\n      <td>242587</td>\n      <td>4</td>\n      <td>41.51106</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"C2bm-KiL0cqc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1593196914470,"user_tz":300,"elapsed":542,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"ba498401-e95e-42e0-eb5a-b99a49a378f8"},"source":["#Validation of distribution of output values\n","df2.groupby(\"target\").count()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":"        danceability  energy    key  loudness   mode  speechiness  \\\ntarget                                                              \n0              20553   20553  20553     20553  20553        20553   \n1              20553   20553  20553     20553  20553        20553   \n\n        acousticness  instrumentalness  liveness  valence  tempo  duration_ms  \\\ntarget                                                                          \n0              20553             20553     20553    20553  20553        20553   \n1              20553             20553     20553    20553  20553        20553   \n\n        time_signature  chorus_hit  sections  \ntarget                                        \n0                20553       20553     20553  \n1                20553       20553     20553  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n      <th>time_signature</th>\n      <th>chorus_hit</th>\n      <th>sections</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n      <td>20553</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"JqlHQ-yC0cqf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1593196916115,"user_tz":300,"elapsed":332,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"cb9bc354-9057-48df-dcc0-a1b923e9f715"},"source":["#Validation of correlation between variables\n","import numpy as np \n","df3=df2.corr()\n","df3"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":"                  danceability    energy       key  loudness      mode  \\\ndanceability          1.000000  0.206128  0.015433  0.274160 -0.032743   \nenergy                0.206128  1.000000  0.022523  0.772628 -0.033780   \nkey                   0.015433  0.022523  1.000000  0.008438 -0.140455   \nloudness              0.274160  0.772628  0.008438  1.000000  0.000509   \nmode                 -0.032743 -0.033780 -0.140455  0.000509  1.000000   \nspeechiness           0.156452  0.122430  0.026515  0.069241 -0.059636   \nacousticness         -0.261252 -0.715088 -0.024178 -0.566548  0.049961   \ninstrumentalness     -0.301915 -0.208153 -0.013101 -0.374301 -0.075992   \nliveness             -0.115251  0.157779  0.000668  0.086708  0.008886   \nvalence               0.553858  0.341427  0.007742  0.271775  0.035636   \ntempo                -0.066541  0.224018  0.001154  0.169453  0.027053   \nduration_ms          -0.063030  0.011830  0.015493 -0.049890 -0.074828   \ntime_signature        0.191664  0.196072  0.004757  0.165520 -0.009483   \nchorus_hit           -0.036277  0.009620  0.010264 -0.013401 -0.022594   \nsections             -0.058615 -0.040233  0.006784 -0.080065 -0.057095   \ntarget                0.346097  0.177142  0.009883  0.286034  0.079614   \n\n                  speechiness  acousticness  instrumentalness  liveness  \\\ndanceability         0.156452     -0.261252         -0.301915 -0.115251   \nenergy               0.122430     -0.715088         -0.208153  0.157779   \nkey                  0.026515     -0.024178         -0.013101  0.000668   \nloudness             0.069241     -0.566548         -0.374301  0.086708   \nmode                -0.059636      0.049961         -0.075992  0.008886   \nspeechiness          1.000000     -0.083948         -0.084092  0.131488   \nacousticness        -0.083948      1.000000          0.204137 -0.030765   \ninstrumentalness    -0.084092      0.204137          1.000000 -0.050582   \nliveness             0.131488     -0.030765         -0.050582  1.000000   \nvalence              0.001528     -0.195331         -0.287047  0.000784   \ntempo                0.036854     -0.179700         -0.053618  0.024861   \nduration_ms          0.007631     -0.070271          0.106551  0.005336   \ntime_signature       0.021085     -0.188139         -0.077980  0.004773   \nchorus_hit           0.012972     -0.012409          0.048654  0.037981   \nsections            -0.008636     -0.016824          0.081188 -0.011742   \ntarget              -0.040835     -0.246036         -0.407638 -0.051445   \n\n                   valence     tempo  duration_ms  time_signature  chorus_hit  \\\ndanceability      0.553858 -0.066541    -0.063030        0.191664   -0.036277   \nenergy            0.341427  0.224018     0.011830        0.196072    0.009620   \nkey               0.007742  0.001154     0.015493        0.004757    0.010264   \nloudness          0.271775  0.169453    -0.049890        0.165520   -0.013401   \nmode              0.035636  0.027053    -0.074828       -0.009483   -0.022594   \nspeechiness       0.001528  0.036854     0.007631        0.021085    0.012972   \nacousticness     -0.195331 -0.179700    -0.070271       -0.188139   -0.012409   \ninstrumentalness -0.287047 -0.053618     0.106551       -0.077980    0.048654   \nliveness          0.000784  0.024861     0.005336        0.004773    0.037981   \nvalence           1.000000  0.107901    -0.172166        0.155669   -0.059120   \ntempo             0.107901  1.000000    -0.024318        0.007659   -0.056054   \nduration_ms      -0.172166 -0.024318     1.000000        0.018454    0.093875   \ntime_signature    0.155669  0.007659     0.018454        1.000000   -0.011281   \nchorus_hit       -0.059120 -0.056054     0.093875       -0.011281    1.000000   \nsections         -0.133527  0.024905     0.888952        0.008424   -0.085920   \ntarget            0.251147  0.032649    -0.073820        0.104884   -0.046409   \n\n                  sections    target  \ndanceability     -0.058615  0.346097  \nenergy           -0.040233  0.177142  \nkey               0.006784  0.009883  \nloudness         -0.080065  0.286034  \nmode             -0.057095  0.079614  \nspeechiness      -0.008636 -0.040835  \nacousticness     -0.016824 -0.246036  \ninstrumentalness  0.081188 -0.407638  \nliveness         -0.011742 -0.051445  \nvalence          -0.133527  0.251147  \ntempo             0.024905  0.032649  \nduration_ms       0.888952 -0.073820  \ntime_signature    0.008424  0.104884  \nchorus_hit       -0.085920 -0.046409  \nsections          1.000000 -0.059997  \ntarget           -0.059997  1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n      <th>time_signature</th>\n      <th>chorus_hit</th>\n      <th>sections</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>danceability</td>\n      <td>1.000000</td>\n      <td>0.206128</td>\n      <td>0.015433</td>\n      <td>0.274160</td>\n      <td>-0.032743</td>\n      <td>0.156452</td>\n      <td>-0.261252</td>\n      <td>-0.301915</td>\n      <td>-0.115251</td>\n      <td>0.553858</td>\n      <td>-0.066541</td>\n      <td>-0.063030</td>\n      <td>0.191664</td>\n      <td>-0.036277</td>\n      <td>-0.058615</td>\n      <td>0.346097</td>\n    </tr>\n    <tr>\n      <td>energy</td>\n      <td>0.206128</td>\n      <td>1.000000</td>\n      <td>0.022523</td>\n      <td>0.772628</td>\n      <td>-0.033780</td>\n      <td>0.122430</td>\n      <td>-0.715088</td>\n      <td>-0.208153</td>\n      <td>0.157779</td>\n      <td>0.341427</td>\n      <td>0.224018</td>\n      <td>0.011830</td>\n      <td>0.196072</td>\n      <td>0.009620</td>\n      <td>-0.040233</td>\n      <td>0.177142</td>\n    </tr>\n    <tr>\n      <td>key</td>\n      <td>0.015433</td>\n      <td>0.022523</td>\n      <td>1.000000</td>\n      <td>0.008438</td>\n      <td>-0.140455</td>\n      <td>0.026515</td>\n      <td>-0.024178</td>\n      <td>-0.013101</td>\n      <td>0.000668</td>\n      <td>0.007742</td>\n      <td>0.001154</td>\n      <td>0.015493</td>\n      <td>0.004757</td>\n      <td>0.010264</td>\n      <td>0.006784</td>\n      <td>0.009883</td>\n    </tr>\n    <tr>\n      <td>loudness</td>\n      <td>0.274160</td>\n      <td>0.772628</td>\n      <td>0.008438</td>\n      <td>1.000000</td>\n      <td>0.000509</td>\n      <td>0.069241</td>\n      <td>-0.566548</td>\n      <td>-0.374301</td>\n      <td>0.086708</td>\n      <td>0.271775</td>\n      <td>0.169453</td>\n      <td>-0.049890</td>\n      <td>0.165520</td>\n      <td>-0.013401</td>\n      <td>-0.080065</td>\n      <td>0.286034</td>\n    </tr>\n    <tr>\n      <td>mode</td>\n      <td>-0.032743</td>\n      <td>-0.033780</td>\n      <td>-0.140455</td>\n      <td>0.000509</td>\n      <td>1.000000</td>\n      <td>-0.059636</td>\n      <td>0.049961</td>\n      <td>-0.075992</td>\n      <td>0.008886</td>\n      <td>0.035636</td>\n      <td>0.027053</td>\n      <td>-0.074828</td>\n      <td>-0.009483</td>\n      <td>-0.022594</td>\n      <td>-0.057095</td>\n      <td>0.079614</td>\n    </tr>\n    <tr>\n      <td>speechiness</td>\n      <td>0.156452</td>\n      <td>0.122430</td>\n      <td>0.026515</td>\n      <td>0.069241</td>\n      <td>-0.059636</td>\n      <td>1.000000</td>\n      <td>-0.083948</td>\n      <td>-0.084092</td>\n      <td>0.131488</td>\n      <td>0.001528</td>\n      <td>0.036854</td>\n      <td>0.007631</td>\n      <td>0.021085</td>\n      <td>0.012972</td>\n      <td>-0.008636</td>\n      <td>-0.040835</td>\n    </tr>\n    <tr>\n      <td>acousticness</td>\n      <td>-0.261252</td>\n      <td>-0.715088</td>\n      <td>-0.024178</td>\n      <td>-0.566548</td>\n      <td>0.049961</td>\n      <td>-0.083948</td>\n      <td>1.000000</td>\n      <td>0.204137</td>\n      <td>-0.030765</td>\n      <td>-0.195331</td>\n      <td>-0.179700</td>\n      <td>-0.070271</td>\n      <td>-0.188139</td>\n      <td>-0.012409</td>\n      <td>-0.016824</td>\n      <td>-0.246036</td>\n    </tr>\n    <tr>\n      <td>instrumentalness</td>\n      <td>-0.301915</td>\n      <td>-0.208153</td>\n      <td>-0.013101</td>\n      <td>-0.374301</td>\n      <td>-0.075992</td>\n      <td>-0.084092</td>\n      <td>0.204137</td>\n      <td>1.000000</td>\n      <td>-0.050582</td>\n      <td>-0.287047</td>\n      <td>-0.053618</td>\n      <td>0.106551</td>\n      <td>-0.077980</td>\n      <td>0.048654</td>\n      <td>0.081188</td>\n      <td>-0.407638</td>\n    </tr>\n    <tr>\n      <td>liveness</td>\n      <td>-0.115251</td>\n      <td>0.157779</td>\n      <td>0.000668</td>\n      <td>0.086708</td>\n      <td>0.008886</td>\n      <td>0.131488</td>\n      <td>-0.030765</td>\n      <td>-0.050582</td>\n      <td>1.000000</td>\n      <td>0.000784</td>\n      <td>0.024861</td>\n      <td>0.005336</td>\n      <td>0.004773</td>\n      <td>0.037981</td>\n      <td>-0.011742</td>\n      <td>-0.051445</td>\n    </tr>\n    <tr>\n      <td>valence</td>\n      <td>0.553858</td>\n      <td>0.341427</td>\n      <td>0.007742</td>\n      <td>0.271775</td>\n      <td>0.035636</td>\n      <td>0.001528</td>\n      <td>-0.195331</td>\n      <td>-0.287047</td>\n      <td>0.000784</td>\n      <td>1.000000</td>\n      <td>0.107901</td>\n      <td>-0.172166</td>\n      <td>0.155669</td>\n      <td>-0.059120</td>\n      <td>-0.133527</td>\n      <td>0.251147</td>\n    </tr>\n    <tr>\n      <td>tempo</td>\n      <td>-0.066541</td>\n      <td>0.224018</td>\n      <td>0.001154</td>\n      <td>0.169453</td>\n      <td>0.027053</td>\n      <td>0.036854</td>\n      <td>-0.179700</td>\n      <td>-0.053618</td>\n      <td>0.024861</td>\n      <td>0.107901</td>\n      <td>1.000000</td>\n      <td>-0.024318</td>\n      <td>0.007659</td>\n      <td>-0.056054</td>\n      <td>0.024905</td>\n      <td>0.032649</td>\n    </tr>\n    <tr>\n      <td>duration_ms</td>\n      <td>-0.063030</td>\n      <td>0.011830</td>\n      <td>0.015493</td>\n      <td>-0.049890</td>\n      <td>-0.074828</td>\n      <td>0.007631</td>\n      <td>-0.070271</td>\n      <td>0.106551</td>\n      <td>0.005336</td>\n      <td>-0.172166</td>\n      <td>-0.024318</td>\n      <td>1.000000</td>\n      <td>0.018454</td>\n      <td>0.093875</td>\n      <td>0.888952</td>\n      <td>-0.073820</td>\n    </tr>\n    <tr>\n      <td>time_signature</td>\n      <td>0.191664</td>\n      <td>0.196072</td>\n      <td>0.004757</td>\n      <td>0.165520</td>\n      <td>-0.009483</td>\n      <td>0.021085</td>\n      <td>-0.188139</td>\n      <td>-0.077980</td>\n      <td>0.004773</td>\n      <td>0.155669</td>\n      <td>0.007659</td>\n      <td>0.018454</td>\n      <td>1.000000</td>\n      <td>-0.011281</td>\n      <td>0.008424</td>\n      <td>0.104884</td>\n    </tr>\n    <tr>\n      <td>chorus_hit</td>\n      <td>-0.036277</td>\n      <td>0.009620</td>\n      <td>0.010264</td>\n      <td>-0.013401</td>\n      <td>-0.022594</td>\n      <td>0.012972</td>\n      <td>-0.012409</td>\n      <td>0.048654</td>\n      <td>0.037981</td>\n      <td>-0.059120</td>\n      <td>-0.056054</td>\n      <td>0.093875</td>\n      <td>-0.011281</td>\n      <td>1.000000</td>\n      <td>-0.085920</td>\n      <td>-0.046409</td>\n    </tr>\n    <tr>\n      <td>sections</td>\n      <td>-0.058615</td>\n      <td>-0.040233</td>\n      <td>0.006784</td>\n      <td>-0.080065</td>\n      <td>-0.057095</td>\n      <td>-0.008636</td>\n      <td>-0.016824</td>\n      <td>0.081188</td>\n      <td>-0.011742</td>\n      <td>-0.133527</td>\n      <td>0.024905</td>\n      <td>0.888952</td>\n      <td>0.008424</td>\n      <td>-0.085920</td>\n      <td>1.000000</td>\n      <td>-0.059997</td>\n    </tr>\n    <tr>\n      <td>target</td>\n      <td>0.346097</td>\n      <td>0.177142</td>\n      <td>0.009883</td>\n      <td>0.286034</td>\n      <td>0.079614</td>\n      <td>-0.040835</td>\n      <td>-0.246036</td>\n      <td>-0.407638</td>\n      <td>-0.051445</td>\n      <td>0.251147</td>\n      <td>0.032649</td>\n      <td>-0.073820</td>\n      <td>0.104884</td>\n      <td>-0.046409</td>\n      <td>-0.059997</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"2bkdcEPG1ibv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196937815,"user_tz":300,"elapsed":7976,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"tags":[]},"source":["# Sin chorus_hit y speechiness\n","data = df2.values\n","X = df2[['danceability', 'energy', 'key', 'loudness','mode', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo', 'duration_ms', 'time_signature', 'sections']]  \n","y = data[:, 15]\n","print(data.shape, X.shape, y.shape)\n","data"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"(41106, 16) (41106, 13) (41106,)\n"},{"output_type":"execute_result","data":{"text/plain":"array([[ 0.578  ,  0.471  ,  4.     , ..., 30.88059, 13.     ,  1.     ],\n       [ 0.704  ,  0.854  , 10.     , ..., 41.51106, 10.     ,  1.     ],\n       [ 0.162  ,  0.836  ,  9.     , ..., 65.32887, 13.     ,  0.     ],\n       ...,\n       [ 0.562  ,  0.314  , 10.     , ..., 21.11763, 10.     ,  1.     ],\n       [ 0.622  ,  0.781  ,  7.     , ..., 47.13558, 11.     ,  0.     ],\n       [ 0.664  ,  0.739  ,  2.     , ..., 42.50341, 14.     ,  1.     ]])"},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"jY2Jscy60cqq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196941239,"user_tz":300,"elapsed":834,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABiuRgdQ0cqt","colab_type":"text"},"source":["## Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"hfEdBDfb0cqu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1593196944475,"user_tz":300,"elapsed":342,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"64bd50bf-4868-46a2-f290-9401841f5581"},"source":["#Scale features (X) using MinMaxScaler\n","from sklearn.preprocessing import MinMaxScaler\n","X_scaler = MinMaxScaler(feature_range=(0,1)).fit(X_train)\n","\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test) \n","\n","X_train_scaled"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[0.78947368, 0.52283395, 0.81818182, ..., 0.05569473, 0.8       ,\n        0.06508876],\n       [0.54048583, 0.83094117, 0.81818182, ..., 0.03957652, 0.8       ,\n        0.04142012],\n       [0.5       , 0.66588373, 0.81818182, ..., 0.03176775, 0.8       ,\n        0.03550296],\n       ...,\n       [0.57692308, 0.36777999, 0.81818182, ..., 0.09203629, 0.8       ,\n        0.09467456],\n       [0.41902834, 0.16070793, 0.63636364, ..., 0.0441886 , 0.8       ,\n        0.04733728],\n       [0.29554656, 0.24873856, 0.81818182, ..., 0.0506431 , 0.6       ,\n        0.06508876]])"},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Uy2UDESH0cqy","colab_type":"text"},"source":["One-hot encode the labels"]},{"cell_type":"code","metadata":{"id":"2bgX_eKc0cqz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1593196947976,"user_tz":300,"elapsed":1876,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"823117d9-f80a-4255-fc73-47fca33d0855"},"source":["#One-hot encode output labels (y)\n","from tensorflow.keras.utils import to_categorical\n","y_train_categorical = to_categorical(y_train)\n","y_test_categorical = to_categorical(y_test)\n","\n","y_train_categorical"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[0., 1.],\n       [1., 0.],\n       [0., 1.],\n       ...,\n       [0., 1.],\n       [0., 1.],\n       [1., 0.]], dtype=float32)"},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"bdxnMFS40cq2","colab_type":"text"},"source":["## Creating and defining our Deep Learning Model Architecture"]},{"cell_type":"code","metadata":{"id":"Vengxhzv0cq3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196965436,"user_tz":300,"elapsed":313,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["#Create a sequential model\n","from tensorflow.keras.models import Sequential\n","model = Sequential() \n","\n","from tensorflow.keras.layers import Dense\n","number_inputs = 13  \n","\n","#Create hidden layers\n","model.add(Dense(units=14,activation='relu', input_dim=number_inputs))\n","model.add(Dense(units=120,activation='relu'))\n","model.add(Dense(units=80,activation='relu'))\n","\n","\n","#Create output layer\n","number_classes = 2\n","model.add(Dense(units=number_classes, activation='softmax')) "],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-z2bcd60cq5","colab_type":"text"},"source":["Number of Hidden Nodes \n","https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=The%20number%20of%20hidden%20neurons,size%20of%20the%20input%20layer."]},{"cell_type":"code","metadata":{"tags":[],"id":"e68kh-j-0cq6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1593196967395,"user_tz":300,"elapsed":388,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"240a8955-0653-4a48-e064-65109ea6ecbc"},"source":["#Model Summary\n","model.summary() "],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 14)                196       \n_________________________________________________________________\ndense_1 (Dense)              (None, 120)               1800      \n_________________________________________________________________\ndense_2 (Dense)              (None, 80)                9680      \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 162       \n=================================================================\nTotal params: 11,838\nTrainable params: 11,838\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"cell_type":"code","metadata":{"id":"wJTml5b60cq9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593196969414,"user_tz":300,"elapsed":440,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}}},"source":["#Compile the Model\n","import tensorflow as tf\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4H8OtKeZ0cq_","colab_type":"text"},"source":["## Training the Model"]},{"cell_type":"code","metadata":{"tags":["outputPrepend"],"id":"-CFXztyU0crA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593197036312,"user_tz":300,"elapsed":64859,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"85fe4fa3-989a-454d-e685-aa5c53888c88"},"source":["#Training the Model\n","import tensorflow as tf\n","\n","history = model.fit(X_train_scaled, y_train_categorical, epochs=500, batch_size=2000, shuffle=True, verbose=2)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"poch 162/500\n16/16 - 0s - loss: 0.4758 - accuracy: 0.7662\nEpoch 163/500\n16/16 - 0s - loss: 0.4754 - accuracy: 0.7664\nEpoch 164/500\n16/16 - 0s - loss: 0.4752 - accuracy: 0.7661\nEpoch 165/500\n16/16 - 0s - loss: 0.4772 - accuracy: 0.7640\nEpoch 166/500\n16/16 - 0s - loss: 0.4753 - accuracy: 0.7668\nEpoch 167/500\n16/16 - 0s - loss: 0.4761 - accuracy: 0.7662\nEpoch 168/500\n16/16 - 0s - loss: 0.4765 - accuracy: 0.7661\nEpoch 169/500\n16/16 - 0s - loss: 0.4771 - accuracy: 0.7659\nEpoch 170/500\n16/16 - 0s - loss: 0.4754 - accuracy: 0.7673\nEpoch 171/500\n16/16 - 0s - loss: 0.4747 - accuracy: 0.7665\nEpoch 172/500\n16/16 - 0s - loss: 0.4753 - accuracy: 0.7673\nEpoch 173/500\n16/16 - 0s - loss: 0.4758 - accuracy: 0.7668\nEpoch 174/500\n16/16 - 0s - loss: 0.4758 - accuracy: 0.7678\nEpoch 175/500\n16/16 - 0s - loss: 0.4758 - accuracy: 0.7672\nEpoch 176/500\n16/16 - 0s - loss: 0.4760 - accuracy: 0.7667\nEpoch 177/500\n16/16 - 0s - loss: 0.4754 - accuracy: 0.7662\nEpoch 178/500\n16/16 - 0s - loss: 0.4764 - accuracy: 0.7662\nEpoch 179/500\n16/16 - 0s - loss: 0.4744 - accuracy: 0.7687\nEpoch 180/500\n16/16 - 0s - loss: 0.4739 - accuracy: 0.7687\nEpoch 181/500\n16/16 - 0s - loss: 0.4740 - accuracy: 0.7669\nEpoch 182/500\n16/16 - 0s - loss: 0.4739 - accuracy: 0.7676\nEpoch 183/500\n16/16 - 0s - loss: 0.4737 - accuracy: 0.7673\nEpoch 184/500\n16/16 - 0s - loss: 0.4745 - accuracy: 0.7668\nEpoch 185/500\n16/16 - 0s - loss: 0.4744 - accuracy: 0.7663\nEpoch 186/500\n16/16 - 0s - loss: 0.4745 - accuracy: 0.7679\nEpoch 187/500\n16/16 - 0s - loss: 0.4730 - accuracy: 0.7683\nEpoch 188/500\n16/16 - 0s - loss: 0.4736 - accuracy: 0.7681\nEpoch 189/500\n16/16 - 0s - loss: 0.4726 - accuracy: 0.7690\nEpoch 190/500\n16/16 - 0s - loss: 0.4732 - accuracy: 0.7690\nEpoch 191/500\n16/16 - 0s - loss: 0.4735 - accuracy: 0.7690\nEpoch 192/500\n16/16 - 0s - loss: 0.4741 - accuracy: 0.7672\nEpoch 193/500\n16/16 - 0s - loss: 0.4730 - accuracy: 0.7684\nEpoch 194/500\n16/16 - 0s - loss: 0.4741 - accuracy: 0.7659\nEpoch 195/500\n16/16 - 0s - loss: 0.4731 - accuracy: 0.7687\nEpoch 196/500\n16/16 - 0s - loss: 0.4730 - accuracy: 0.7683\nEpoch 197/500\n16/16 - 0s - loss: 0.4732 - accuracy: 0.7697\nEpoch 198/500\n16/16 - 0s - loss: 0.4727 - accuracy: 0.7685\nEpoch 199/500\n16/16 - 0s - loss: 0.4725 - accuracy: 0.7687\nEpoch 200/500\n16/16 - 0s - loss: 0.4729 - accuracy: 0.7688\nEpoch 201/500\n16/16 - 0s - loss: 0.4726 - accuracy: 0.7687\nEpoch 202/500\n16/16 - 0s - loss: 0.4727 - accuracy: 0.7679\nEpoch 203/500\n16/16 - 0s - loss: 0.4717 - accuracy: 0.7684\nEpoch 204/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7699\nEpoch 205/500\n16/16 - 0s - loss: 0.4736 - accuracy: 0.7689\nEpoch 206/500\n16/16 - 0s - loss: 0.4719 - accuracy: 0.7682\nEpoch 207/500\n16/16 - 0s - loss: 0.4749 - accuracy: 0.7659\nEpoch 208/500\n16/16 - 0s - loss: 0.4732 - accuracy: 0.7676\nEpoch 209/500\n16/16 - 0s - loss: 0.4732 - accuracy: 0.7680\nEpoch 210/500\n16/16 - 0s - loss: 0.4739 - accuracy: 0.7675\nEpoch 211/500\n16/16 - 0s - loss: 0.4711 - accuracy: 0.7697\nEpoch 212/500\n16/16 - 0s - loss: 0.4707 - accuracy: 0.7689\nEpoch 213/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7701\nEpoch 214/500\n16/16 - 0s - loss: 0.4717 - accuracy: 0.7690\nEpoch 215/500\n16/16 - 0s - loss: 0.4708 - accuracy: 0.7701\nEpoch 216/500\n16/16 - 0s - loss: 0.4717 - accuracy: 0.7678\nEpoch 217/500\n16/16 - 0s - loss: 0.4704 - accuracy: 0.7693\nEpoch 218/500\n16/16 - 0s - loss: 0.4718 - accuracy: 0.7695\nEpoch 219/500\n16/16 - 0s - loss: 0.4704 - accuracy: 0.7693\nEpoch 220/500\n16/16 - 0s - loss: 0.4705 - accuracy: 0.7701\nEpoch 221/500\n16/16 - 0s - loss: 0.4700 - accuracy: 0.7704\nEpoch 222/500\n16/16 - 0s - loss: 0.4699 - accuracy: 0.7708\nEpoch 223/500\n16/16 - 0s - loss: 0.4705 - accuracy: 0.7706\nEpoch 224/500\n16/16 - 0s - loss: 0.4706 - accuracy: 0.7700\nEpoch 225/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7703\nEpoch 226/500\n16/16 - 0s - loss: 0.4693 - accuracy: 0.7707\nEpoch 227/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7708\nEpoch 228/500\n16/16 - 0s - loss: 0.4694 - accuracy: 0.7705\nEpoch 229/500\n16/16 - 0s - loss: 0.4697 - accuracy: 0.7711\nEpoch 230/500\n16/16 - 0s - loss: 0.4691 - accuracy: 0.7718\nEpoch 231/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7694\nEpoch 232/500\n16/16 - 0s - loss: 0.4699 - accuracy: 0.7698\nEpoch 233/500\n16/16 - 0s - loss: 0.4698 - accuracy: 0.7700\nEpoch 234/500\n16/16 - 0s - loss: 0.4703 - accuracy: 0.7687\nEpoch 235/500\n16/16 - 0s - loss: 0.4718 - accuracy: 0.7691\nEpoch 236/500\n16/16 - 0s - loss: 0.4704 - accuracy: 0.7697\nEpoch 237/500\n16/16 - 0s - loss: 0.4694 - accuracy: 0.7704\nEpoch 238/500\n16/16 - 0s - loss: 0.4691 - accuracy: 0.7716\nEpoch 239/500\n16/16 - 0s - loss: 0.4689 - accuracy: 0.7699\nEpoch 240/500\n16/16 - 0s - loss: 0.4687 - accuracy: 0.7706\nEpoch 241/500\n16/16 - 0s - loss: 0.4679 - accuracy: 0.7718\nEpoch 242/500\n16/16 - 0s - loss: 0.4680 - accuracy: 0.7713\nEpoch 243/500\n16/16 - 0s - loss: 0.4683 - accuracy: 0.7697\nEpoch 244/500\n16/16 - 0s - loss: 0.4682 - accuracy: 0.7702\nEpoch 245/500\n16/16 - 0s - loss: 0.4688 - accuracy: 0.7698\nEpoch 246/500\n16/16 - 0s - loss: 0.4682 - accuracy: 0.7713\nEpoch 247/500\n16/16 - 0s - loss: 0.4684 - accuracy: 0.7702\nEpoch 248/500\n16/16 - 0s - loss: 0.4712 - accuracy: 0.7685\nEpoch 249/500\n16/16 - 0s - loss: 0.4727 - accuracy: 0.7681\nEpoch 250/500\n16/16 - 0s - loss: 0.4691 - accuracy: 0.7704\nEpoch 251/500\n16/16 - 0s - loss: 0.4680 - accuracy: 0.7706\nEpoch 252/500\n16/16 - 0s - loss: 0.4689 - accuracy: 0.7693\nEpoch 253/500\n16/16 - 0s - loss: 0.4681 - accuracy: 0.7700\nEpoch 254/500\n16/16 - 0s - loss: 0.4683 - accuracy: 0.7715\nEpoch 255/500\n16/16 - 0s - loss: 0.4679 - accuracy: 0.7713\nEpoch 256/500\n16/16 - 0s - loss: 0.4683 - accuracy: 0.7715\nEpoch 257/500\n16/16 - 0s - loss: 0.4678 - accuracy: 0.7716\nEpoch 258/500\n16/16 - 0s - loss: 0.4677 - accuracy: 0.7711\nEpoch 259/500\n16/16 - 0s - loss: 0.4671 - accuracy: 0.7708\nEpoch 260/500\n16/16 - 0s - loss: 0.4672 - accuracy: 0.7707\nEpoch 261/500\n16/16 - 0s - loss: 0.4673 - accuracy: 0.7710\nEpoch 262/500\n16/16 - 0s - loss: 0.4675 - accuracy: 0.7711\nEpoch 263/500\n16/16 - 0s - loss: 0.4679 - accuracy: 0.7702\nEpoch 264/500\n16/16 - 0s - loss: 0.4665 - accuracy: 0.7720\nEpoch 265/500\n16/16 - 0s - loss: 0.4681 - accuracy: 0.7711\nEpoch 266/500\n16/16 - 0s - loss: 0.4672 - accuracy: 0.7720\nEpoch 267/500\n16/16 - 0s - loss: 0.4665 - accuracy: 0.7712\nEpoch 268/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7727\nEpoch 269/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7706\nEpoch 270/500\n16/16 - 0s - loss: 0.4671 - accuracy: 0.7712\nEpoch 271/500\n16/16 - 0s - loss: 0.4665 - accuracy: 0.7718\nEpoch 272/500\n16/16 - 0s - loss: 0.4667 - accuracy: 0.7725\nEpoch 273/500\n16/16 - 0s - loss: 0.4657 - accuracy: 0.7715\nEpoch 274/500\n16/16 - 0s - loss: 0.4656 - accuracy: 0.7723\nEpoch 275/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7707\nEpoch 276/500\n16/16 - 0s - loss: 0.4656 - accuracy: 0.7723\nEpoch 277/500\n16/16 - 0s - loss: 0.4664 - accuracy: 0.7709\nEpoch 278/500\n16/16 - 0s - loss: 0.4666 - accuracy: 0.7721\nEpoch 279/500\n16/16 - 0s - loss: 0.4664 - accuracy: 0.7727\nEpoch 280/500\n16/16 - 0s - loss: 0.4651 - accuracy: 0.7719\nEpoch 281/500\n16/16 - 0s - loss: 0.4660 - accuracy: 0.7710\nEpoch 282/500\n16/16 - 0s - loss: 0.4667 - accuracy: 0.7704\nEpoch 283/500\n16/16 - 0s - loss: 0.4664 - accuracy: 0.7715\nEpoch 284/500\n16/16 - 0s - loss: 0.4653 - accuracy: 0.7719\nEpoch 285/500\n16/16 - 0s - loss: 0.4648 - accuracy: 0.7721\nEpoch 286/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7718\nEpoch 287/500\n16/16 - 0s - loss: 0.4645 - accuracy: 0.7726\nEpoch 288/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7722\nEpoch 289/500\n16/16 - 0s - loss: 0.4650 - accuracy: 0.7729\nEpoch 290/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7714\nEpoch 291/500\n16/16 - 0s - loss: 0.4646 - accuracy: 0.7726\nEpoch 292/500\n16/16 - 0s - loss: 0.4650 - accuracy: 0.7726\nEpoch 293/500\n16/16 - 0s - loss: 0.4657 - accuracy: 0.7729\nEpoch 294/500\n16/16 - 0s - loss: 0.4653 - accuracy: 0.7723\nEpoch 295/500\n16/16 - 0s - loss: 0.4654 - accuracy: 0.7721\nEpoch 296/500\n16/16 - 0s - loss: 0.4651 - accuracy: 0.7739\nEpoch 297/500\n16/16 - 0s - loss: 0.4642 - accuracy: 0.7738\nEpoch 298/500\n16/16 - 0s - loss: 0.4658 - accuracy: 0.7724\nEpoch 299/500\n16/16 - 0s - loss: 0.4663 - accuracy: 0.7715\nEpoch 300/500\n16/16 - 0s - loss: 0.4647 - accuracy: 0.7727\nEpoch 301/500\n16/16 - 0s - loss: 0.4642 - accuracy: 0.7735\nEpoch 302/500\n16/16 - 0s - loss: 0.4636 - accuracy: 0.7735\nEpoch 303/500\n16/16 - 0s - loss: 0.4636 - accuracy: 0.7735\nEpoch 304/500\n16/16 - 0s - loss: 0.4634 - accuracy: 0.7743\nEpoch 305/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7729\nEpoch 306/500\n16/16 - 0s - loss: 0.4636 - accuracy: 0.7736\nEpoch 307/500\n16/16 - 0s - loss: 0.4651 - accuracy: 0.7721\nEpoch 308/500\n16/16 - 0s - loss: 0.4640 - accuracy: 0.7730\nEpoch 309/500\n16/16 - 0s - loss: 0.4642 - accuracy: 0.7728\nEpoch 310/500\n16/16 - 0s - loss: 0.4631 - accuracy: 0.7733\nEpoch 311/500\n16/16 - 0s - loss: 0.4630 - accuracy: 0.7735\nEpoch 312/500\n16/16 - 0s - loss: 0.4655 - accuracy: 0.7724\nEpoch 313/500\n16/16 - 0s - loss: 0.4655 - accuracy: 0.7719\nEpoch 314/500\n16/16 - 0s - loss: 0.4634 - accuracy: 0.7732\nEpoch 315/500\n16/16 - 0s - loss: 0.4644 - accuracy: 0.7716\nEpoch 316/500\n16/16 - 0s - loss: 0.4649 - accuracy: 0.7736\nEpoch 317/500\n16/16 - 0s - loss: 0.4639 - accuracy: 0.7716\nEpoch 318/500\n16/16 - 0s - loss: 0.4638 - accuracy: 0.7733\nEpoch 319/500\n16/16 - 0s - loss: 0.4632 - accuracy: 0.7738\nEpoch 320/500\n16/16 - 0s - loss: 0.4638 - accuracy: 0.7731\nEpoch 321/500\n16/16 - 0s - loss: 0.4662 - accuracy: 0.7718\nEpoch 322/500\n16/16 - 0s - loss: 0.4633 - accuracy: 0.7740\nEpoch 323/500\n16/16 - 0s - loss: 0.4641 - accuracy: 0.7731\nEpoch 324/500\n16/16 - 0s - loss: 0.4629 - accuracy: 0.7731\nEpoch 325/500\n16/16 - 0s - loss: 0.4618 - accuracy: 0.7753\nEpoch 326/500\n16/16 - 0s - loss: 0.4621 - accuracy: 0.7748\nEpoch 327/500\n16/16 - 0s - loss: 0.4619 - accuracy: 0.7740\nEpoch 328/500\n16/16 - 0s - loss: 0.4623 - accuracy: 0.7750\nEpoch 329/500\n16/16 - 0s - loss: 0.4625 - accuracy: 0.7733\nEpoch 330/500\n16/16 - 0s - loss: 0.4625 - accuracy: 0.7742\nEpoch 331/500\n16/16 - 0s - loss: 0.4625 - accuracy: 0.7738\nEpoch 332/500\n16/16 - 0s - loss: 0.4615 - accuracy: 0.7758\nEpoch 333/500\n16/16 - 0s - loss: 0.4620 - accuracy: 0.7758\nEpoch 334/500\n16/16 - 0s - loss: 0.4627 - accuracy: 0.7739\nEpoch 335/500\n16/16 - 0s - loss: 0.4635 - accuracy: 0.7751\nEpoch 336/500\n16/16 - 0s - loss: 0.4626 - accuracy: 0.7732\nEpoch 337/500\n16/16 - 0s - loss: 0.4636 - accuracy: 0.7736\nEpoch 338/500\n16/16 - 0s - loss: 0.4626 - accuracy: 0.7742\nEpoch 339/500\n16/16 - 0s - loss: 0.4620 - accuracy: 0.7750\nEpoch 340/500\n16/16 - 0s - loss: 0.4632 - accuracy: 0.7738\nEpoch 341/500\n16/16 - 0s - loss: 0.4623 - accuracy: 0.7734\nEpoch 342/500\n16/16 - 0s - loss: 0.4614 - accuracy: 0.7743\nEpoch 343/500\n16/16 - 0s - loss: 0.4618 - accuracy: 0.7752\nEpoch 344/500\n16/16 - 0s - loss: 0.4609 - accuracy: 0.7738\nEpoch 345/500\n16/16 - 0s - loss: 0.4623 - accuracy: 0.7738\nEpoch 346/500\n16/16 - 0s - loss: 0.4627 - accuracy: 0.7735\nEpoch 347/500\n16/16 - 0s - loss: 0.4625 - accuracy: 0.7739\nEpoch 348/500\n16/16 - 0s - loss: 0.4623 - accuracy: 0.7741\nEpoch 349/500\n16/16 - 0s - loss: 0.4608 - accuracy: 0.7748\nEpoch 350/500\n16/16 - 0s - loss: 0.4626 - accuracy: 0.7749\nEpoch 351/500\n16/16 - 0s - loss: 0.4608 - accuracy: 0.7765\nEpoch 352/500\n16/16 - 0s - loss: 0.4608 - accuracy: 0.7761\nEpoch 353/500\n16/16 - 0s - loss: 0.4617 - accuracy: 0.7747\nEpoch 354/500\n16/16 - 0s - loss: 0.4608 - accuracy: 0.7759\nEpoch 355/500\n16/16 - 0s - loss: 0.4598 - accuracy: 0.7754\nEpoch 356/500\n16/16 - 0s - loss: 0.4607 - accuracy: 0.7749\nEpoch 357/500\n16/16 - 0s - loss: 0.4620 - accuracy: 0.7738\nEpoch 358/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7746\nEpoch 359/500\n16/16 - 0s - loss: 0.4614 - accuracy: 0.7733\nEpoch 360/500\n16/16 - 0s - loss: 0.4619 - accuracy: 0.7736\nEpoch 361/500\n16/16 - 0s - loss: 0.4603 - accuracy: 0.7749\nEpoch 362/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7741\nEpoch 363/500\n16/16 - 0s - loss: 0.4616 - accuracy: 0.7753\nEpoch 364/500\n16/16 - 0s - loss: 0.4634 - accuracy: 0.7732\nEpoch 365/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7749\nEpoch 366/500\n16/16 - 0s - loss: 0.4602 - accuracy: 0.7748\nEpoch 367/500\n16/16 - 0s - loss: 0.4605 - accuracy: 0.7756\nEpoch 368/500\n16/16 - 0s - loss: 0.4592 - accuracy: 0.7757\nEpoch 369/500\n16/16 - 0s - loss: 0.4595 - accuracy: 0.7760\nEpoch 370/500\n16/16 - 0s - loss: 0.4604 - accuracy: 0.7747\nEpoch 371/500\n16/16 - 0s - loss: 0.4597 - accuracy: 0.7753\nEpoch 372/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7746\nEpoch 373/500\n16/16 - 0s - loss: 0.4599 - accuracy: 0.7755\nEpoch 374/500\n16/16 - 0s - loss: 0.4592 - accuracy: 0.7761\nEpoch 375/500\n16/16 - 0s - loss: 0.4602 - accuracy: 0.7738\nEpoch 376/500\n16/16 - 0s - loss: 0.4597 - accuracy: 0.7754\nEpoch 377/500\n16/16 - 0s - loss: 0.4598 - accuracy: 0.7757\nEpoch 378/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7737\nEpoch 379/500\n16/16 - 0s - loss: 0.4593 - accuracy: 0.7736\nEpoch 380/500\n16/16 - 0s - loss: 0.4589 - accuracy: 0.7773\nEpoch 381/500\n16/16 - 0s - loss: 0.4590 - accuracy: 0.7759\nEpoch 382/500\n16/16 - 0s - loss: 0.4596 - accuracy: 0.7761\nEpoch 383/500\n16/16 - 0s - loss: 0.4596 - accuracy: 0.7757\nEpoch 384/500\n16/16 - 0s - loss: 0.4600 - accuracy: 0.7750\nEpoch 385/500\n16/16 - 0s - loss: 0.4587 - accuracy: 0.7767\nEpoch 386/500\n16/16 - 0s - loss: 0.4579 - accuracy: 0.7762\nEpoch 387/500\n16/16 - 0s - loss: 0.4598 - accuracy: 0.7747\nEpoch 388/500\n16/16 - 0s - loss: 0.4587 - accuracy: 0.7764\nEpoch 389/500\n16/16 - 0s - loss: 0.4594 - accuracy: 0.7755\nEpoch 390/500\n16/16 - 0s - loss: 0.4588 - accuracy: 0.7758\nEpoch 391/500\n16/16 - 0s - loss: 0.4592 - accuracy: 0.7759\nEpoch 392/500\n16/16 - 0s - loss: 0.4584 - accuracy: 0.7769\nEpoch 393/500\n16/16 - 0s - loss: 0.4593 - accuracy: 0.7762\nEpoch 394/500\n16/16 - 0s - loss: 0.4595 - accuracy: 0.7758\nEpoch 395/500\n16/16 - 0s - loss: 0.4589 - accuracy: 0.7752\nEpoch 396/500\n16/16 - 0s - loss: 0.4588 - accuracy: 0.7753\nEpoch 397/500\n16/16 - 0s - loss: 0.4609 - accuracy: 0.7742\nEpoch 398/500\n16/16 - 0s - loss: 0.4613 - accuracy: 0.7754\nEpoch 399/500\n16/16 - 0s - loss: 0.4601 - accuracy: 0.7740\nEpoch 400/500\n16/16 - 0s - loss: 0.4591 - accuracy: 0.7757\nEpoch 401/500\n16/16 - 0s - loss: 0.4584 - accuracy: 0.7774\nEpoch 402/500\n16/16 - 0s - loss: 0.4598 - accuracy: 0.7750\nEpoch 403/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7779\nEpoch 404/500\n16/16 - 0s - loss: 0.4595 - accuracy: 0.7740\nEpoch 405/500\n16/16 - 0s - loss: 0.4579 - accuracy: 0.7757\nEpoch 406/500\n16/16 - 0s - loss: 0.4584 - accuracy: 0.7766\nEpoch 407/500\n16/16 - 0s - loss: 0.4574 - accuracy: 0.7764\nEpoch 408/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7761\nEpoch 409/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7760\nEpoch 410/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7762\nEpoch 411/500\n16/16 - 0s - loss: 0.4566 - accuracy: 0.7776\nEpoch 412/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7769\nEpoch 413/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7769\nEpoch 414/500\n16/16 - 0s - loss: 0.4569 - accuracy: 0.7765\nEpoch 415/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7767\nEpoch 416/500\n16/16 - 0s - loss: 0.4576 - accuracy: 0.7764\nEpoch 417/500\n16/16 - 0s - loss: 0.4569 - accuracy: 0.7776\nEpoch 418/500\n16/16 - 0s - loss: 0.4566 - accuracy: 0.7775\nEpoch 419/500\n16/16 - 0s - loss: 0.4570 - accuracy: 0.7763\nEpoch 420/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7766\nEpoch 421/500\n16/16 - 0s - loss: 0.4564 - accuracy: 0.7786\nEpoch 422/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7772\nEpoch 423/500\n16/16 - 0s - loss: 0.4581 - accuracy: 0.7765\nEpoch 424/500\n16/16 - 0s - loss: 0.4557 - accuracy: 0.7787\nEpoch 425/500\n16/16 - 0s - loss: 0.4563 - accuracy: 0.7774\nEpoch 426/500\n16/16 - 0s - loss: 0.4564 - accuracy: 0.7771\nEpoch 427/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7784\nEpoch 428/500\n16/16 - 0s - loss: 0.4567 - accuracy: 0.7770\nEpoch 429/500\n16/16 - 0s - loss: 0.4560 - accuracy: 0.7765\nEpoch 430/500\n16/16 - 0s - loss: 0.4573 - accuracy: 0.7767\nEpoch 431/500\n16/16 - 0s - loss: 0.4560 - accuracy: 0.7777\nEpoch 432/500\n16/16 - 0s - loss: 0.4569 - accuracy: 0.7780\nEpoch 433/500\n16/16 - 0s - loss: 0.4555 - accuracy: 0.7780\nEpoch 434/500\n16/16 - 0s - loss: 0.4555 - accuracy: 0.7773\nEpoch 435/500\n16/16 - 0s - loss: 0.4567 - accuracy: 0.7771\nEpoch 436/500\n16/16 - 0s - loss: 0.4572 - accuracy: 0.7764\nEpoch 437/500\n16/16 - 0s - loss: 0.4556 - accuracy: 0.7780\nEpoch 438/500\n16/16 - 0s - loss: 0.4586 - accuracy: 0.7753\nEpoch 439/500\n16/16 - 0s - loss: 0.4558 - accuracy: 0.7775\nEpoch 440/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7774\nEpoch 441/500\n16/16 - 0s - loss: 0.4549 - accuracy: 0.7793\nEpoch 442/500\n16/16 - 0s - loss: 0.4554 - accuracy: 0.7778\nEpoch 443/500\n16/16 - 0s - loss: 0.4549 - accuracy: 0.7782\nEpoch 444/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7762\nEpoch 445/500\n16/16 - 0s - loss: 0.4598 - accuracy: 0.7737\nEpoch 446/500\n16/16 - 0s - loss: 0.4549 - accuracy: 0.7778\nEpoch 447/500\n16/16 - 0s - loss: 0.4552 - accuracy: 0.7796\nEpoch 448/500\n16/16 - 0s - loss: 0.4557 - accuracy: 0.7770\nEpoch 449/500\n16/16 - 0s - loss: 0.4589 - accuracy: 0.7774\nEpoch 450/500\n16/16 - 0s - loss: 0.4571 - accuracy: 0.7766\nEpoch 451/500\n16/16 - 0s - loss: 0.4556 - accuracy: 0.7768\nEpoch 452/500\n16/16 - 0s - loss: 0.4554 - accuracy: 0.7775\nEpoch 453/500\n16/16 - 0s - loss: 0.4556 - accuracy: 0.7786\nEpoch 454/500\n16/16 - 0s - loss: 0.4551 - accuracy: 0.7779\nEpoch 455/500\n16/16 - 0s - loss: 0.4550 - accuracy: 0.7775\nEpoch 456/500\n16/16 - 0s - loss: 0.4552 - accuracy: 0.7774\nEpoch 457/500\n16/16 - 0s - loss: 0.4547 - accuracy: 0.7778\nEpoch 458/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7795\nEpoch 459/500\n16/16 - 0s - loss: 0.4551 - accuracy: 0.7766\nEpoch 460/500\n16/16 - 0s - loss: 0.4553 - accuracy: 0.7795\nEpoch 461/500\n16/16 - 0s - loss: 0.4542 - accuracy: 0.7790\nEpoch 462/500\n16/16 - 0s - loss: 0.4552 - accuracy: 0.7766\nEpoch 463/500\n16/16 - 0s - loss: 0.4568 - accuracy: 0.7777\nEpoch 464/500\n16/16 - 0s - loss: 0.4562 - accuracy: 0.7781\nEpoch 465/500\n16/16 - 0s - loss: 0.4551 - accuracy: 0.7783\nEpoch 466/500\n16/16 - 0s - loss: 0.4583 - accuracy: 0.7751\nEpoch 467/500\n16/16 - 0s - loss: 0.4558 - accuracy: 0.7770\nEpoch 468/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7789\nEpoch 469/500\n16/16 - 0s - loss: 0.4542 - accuracy: 0.7780\nEpoch 470/500\n16/16 - 0s - loss: 0.4535 - accuracy: 0.7783\nEpoch 471/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7778\nEpoch 472/500\n16/16 - 0s - loss: 0.4536 - accuracy: 0.7786\nEpoch 473/500\n16/16 - 0s - loss: 0.4538 - accuracy: 0.7796\nEpoch 474/500\n16/16 - 0s - loss: 0.4536 - accuracy: 0.7789\nEpoch 475/500\n16/16 - 0s - loss: 0.4536 - accuracy: 0.7794\nEpoch 476/500\n16/16 - 0s - loss: 0.4559 - accuracy: 0.7779\nEpoch 477/500\n16/16 - 0s - loss: 0.4536 - accuracy: 0.7794\nEpoch 478/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7799\nEpoch 479/500\n16/16 - 0s - loss: 0.4543 - accuracy: 0.7787\nEpoch 480/500\n16/16 - 0s - loss: 0.4542 - accuracy: 0.7789\nEpoch 481/500\n16/16 - 0s - loss: 0.4532 - accuracy: 0.7791\nEpoch 482/500\n16/16 - 0s - loss: 0.4536 - accuracy: 0.7794\nEpoch 483/500\n16/16 - 0s - loss: 0.4529 - accuracy: 0.7801\nEpoch 484/500\n16/16 - 0s - loss: 0.4524 - accuracy: 0.7795\nEpoch 485/500\n16/16 - 0s - loss: 0.4533 - accuracy: 0.7798\nEpoch 486/500\n16/16 - 0s - loss: 0.4533 - accuracy: 0.7790\nEpoch 487/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7803\nEpoch 488/500\n16/16 - 0s - loss: 0.4546 - accuracy: 0.7778\nEpoch 489/500\n16/16 - 0s - loss: 0.4534 - accuracy: 0.7792\nEpoch 490/500\n16/16 - 0s - loss: 0.4558 - accuracy: 0.7770\nEpoch 491/500\n16/16 - 0s - loss: 0.4531 - accuracy: 0.7799\nEpoch 492/500\n16/16 - 0s - loss: 0.4527 - accuracy: 0.7809\nEpoch 493/500\n16/16 - 0s - loss: 0.4515 - accuracy: 0.7799\nEpoch 494/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7809\nEpoch 495/500\n16/16 - 0s - loss: 0.4536 - accuracy: 0.7808\nEpoch 496/500\n16/16 - 0s - loss: 0.4526 - accuracy: 0.7789\nEpoch 497/500\n16/16 - 0s - loss: 0.4523 - accuracy: 0.7801\nEpoch 498/500\n16/16 - 0s - loss: 0.4525 - accuracy: 0.7792\nEpoch 499/500\n16/16 - 0s - loss: 0.4522 - accuracy: 0.7799\nEpoch 500/500\n16/16 - 0s - loss: 0.4533 - accuracy: 0.7801\n"}]},{"cell_type":"markdown","metadata":{"id":"S_ZowJis0crC","colab_type":"text"},"source":["## Validation of the Model"]},{"cell_type":"code","metadata":{"tags":[],"id":"wcN4ybhW0crD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593197040987,"user_tz":300,"elapsed":822,"user":{"displayName":"Grecia Villarreal","photoUrl":"","userId":"04417287800158359907"}},"outputId":"3e76aedc-db46-478e-a813-3a00c4339c85"},"source":["#Evaluate the Model using the testing data\n","#Compare Model performace between training and testing data\n","model_loss_train, model_accuracy_train = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n","model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n","\n","print(f\"TRAINING DATA --> Loss: {model_loss_train}, Accuracy: {model_accuracy_train}\")    \n","print(f\"TESTING DATA --> Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"964/964 - 2s - loss: 0.4539 - accuracy: 0.7797\n322/322 - 1s - loss: 0.4871 - accuracy: 0.7718\nTRAINING DATA --> Loss: 0.45387256145477295, Accuracy: 0.7796555161476135\nTESTING DATA --> Loss: 0.4871175289154053, Accuracy: 0.7718205451965332\n"}]},{"cell_type":"markdown","metadata":{"id":"5iOzWcF50crF","colab_type":"text"},"source":["## Saving the Trained Model"]},{"cell_type":"code","metadata":{"id":"13uMQTlH0crG","colab_type":"code","colab":{}},"source":["# # Save the model\n","# Define working directory\n","#os.chdir(r\"C:\\Users\\hguzm\\Documents\\000. Personal\\Bootcamp\\Proyectos\\FinalProject-Spotify\")\n","#model.save(\"spotify_DeepLearning_Model.h5\")"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6dYRUJMs0crJ","colab_type":"text"},"source":["## Loading a Model"]},{"cell_type":"code","metadata":{"id":"1beJ-J6k0crJ","colab_type":"code","colab":{}},"source":["# # Load the model  \n","# from tensorflow.keras.models import load_model\n","# # Define working directory\n","# os.chdir(r\"C:\\Users\\hguzm\\Documents\\000. Personal\\Bootcamp\\Proyectos\\FinalProject-Spotify\")\n","# model = load_model(\"spotify_DeepLearning_Model.h5\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"35f9x40J0crM","colab_type":"code","colab":{},"outputId":"12d0cef2-1e2d-4ca4-f734-8c96881be198"},"source":["model.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 14)                196       \n_________________________________________________________________\ndense_1 (Dense)              (None, 120)               1800      \n_________________________________________________________________\ndense_2 (Dense)              (None, 80)                9680      \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 162       \n=================================================================\nTotal params: 11,838\nTrainable params: 11,838\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"cell_type":"markdown","metadata":{"id":"csQ0sXEf0crO","colab_type":"text"},"source":["## Validation of the Model"]},{"cell_type":"code","metadata":{"tags":[],"id":"I5WF280V0crP","colab_type":"code","colab":{},"outputId":"4f6c83c2-fd70-427a-e249-9f928abb553b"},"source":["# #Evaluate the Model using the testing data\n","# model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n","    \n","# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"BdBgyOh60crR","colab_type":"code","colab":{}},"source":["# #Making Predictions with new data\n","# new_data = np.array([[0.2, 0.3, 0.4,0.2, 0.3, 0.4,0.2, 0.3, 0.4,0.2, 0.3, 0.4,0.2, 0.3, 0.4]])  # AQUI IRIA INFORMACIÓN DEL API\n","# print(f\"Predicted class: {model.predict_classes(new_data)}\")"],"execution_count":21,"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"orig_nbformat":2,"kernelspec":{"name":"python37464bitbaseconda621df6d49d2c4311a89d7503a44084b1","display_name":"Python 3.7.4 64-bit ('base': conda)"},"colab":{"name":"model_v2_Grecia2.ipynb","provenance":[{"file_id":"11wI5Qfi-s_wzKnroqXDrvjKOaF8fJka3","timestamp":1593196456960}]}},"nbformat":4,"nbformat_minor":0}